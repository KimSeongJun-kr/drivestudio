import torch
import numpy as np
import json
import os
from collections import OrderedDict
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import argparse
from nuscenes.nuscenes import NuScenes
from scipy.spatial.transform import Rotation as R
from pyquaternion import Quaternion
import glob

@dataclass
class PoseAnnotation:
    """DriveStudio í¬ì¦ˆ ë°ì´í„°ë¥¼ NuScenes annotation í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤"""
    token: str                           # ê³ ìœ  í† í°
    sample_token: str                    # ìƒ˜í”Œ í† í° (NuScenes í‚¤í”„ë ˆì„ê³¼ ë§¤ì¹­)
    instance_token: str                  # ì¸ìŠ¤í„´ìŠ¤ í† í°
    visibility_token: str                # ê°€ì‹œì„± í† í° (ê¸°ë³¸ê°’ "4")
    attribute_tokens: List[str]          # ì†ì„± í† í°ë“¤
    translation: List[float]             # [x, y, z]
    size: List[float]                   # [w, l, h]
    rotation: List[float]               # quaternion [w, x, y, z]
    prev: str                           # ì´ì „ annotation í† í°
    next: str                           # ë‹¤ìŒ annotation í† í°
    num_lidar_pts: int                  # ë¼ì´ë‹¤ í¬ì¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’ 0)
    num_radar_pts: int                  # ë ˆì´ë” í¬ì¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’ 0)
    velocity: List[float]               # [vx, vy] ì†ë„
    detection_name: str                 # íƒì§€ ê°ì²´ ì´ë¦„
    detection_score: float              # íƒì§€ ì ìˆ˜
    attribute_name: str                 # ì†ì„± ì´ë¦„
    
    # DriveStudio ì¶”ê°€ ì •ë³´
    instance_id: int                    # ì¸ìŠ¤í„´ìŠ¤ ID (0~190)
    time_frame: int                     # ì‹œê°„ í”„ë ˆì„
    node_type: str                      # 'RigidNodes', 'SMPLNodes', 'DeformableNodes'
    confidence: float = 1.0             # ì‹ ë¢°ë„
    scene_token: str = ""               # NuScenes scene í† í°
    scene_name: str = ""                # NuScenes scene ì´ë¦„

def get_nuscenes_scene_info(dataroot: str, scene_name: str, version: str = 'v1.0-mini') -> Tuple[str, str, List[str]]:
    """NuScenes scene ì´ë¦„ìœ¼ë¡œ scene ì •ë³´ì™€ sample í† í°ë“¤ì„ ê°€ì ¸ì˜´"""
    try:
        nusc = NuScenes(version=version, dataroot=dataroot, verbose=False)
        
        # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
        scene = None
        for s in nusc.scene:
            if s['name'] == scene_name:
                scene = s
                break
                
        if scene is None:
            print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "", "", []
            
        # sceneì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œë¶€í„° ì‹œì‘
        sample = nusc.get('sample', scene['first_sample_token'])
        sample_tokens = []
        
        while True:
            sample_tokens.append(sample['token'])
            if sample['next'] == '':
                break
            sample = nusc.get('sample', sample['next'])
            
        return scene['token'], scene['name'], sample_tokens
        
    except Exception as e:
        print(f"âš ï¸ NuScenes scene ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return "", "", []

def get_camera_front_start_pose(nuscenes_dataroot: str, scene_name: str, version: str = 'v1.0-mini') -> Optional[np.ndarray]:
    """NuScenes ì²« ë²ˆì§¸ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ê°€ì ¸ì˜´ (ì¢Œí‘œ ì •ë ¬ìš©)"""
    try:
        # NuScenes API ì´ˆê¸°í™”
        nusc = NuScenes(version=version, dataroot=nuscenes_dataroot, verbose=False)
        
        # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
        scene = None
        for s in nusc.scene:
            if s['name'] == scene_name:
                scene = s
                break
                
        if scene is None:
            print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # ì²« ë²ˆì§¸ sample ê°€ì ¸ì˜¤ê¸°
        first_sample_token = scene['first_sample_token']
        first_sample_record = nusc.get('sample', first_sample_token)
        
        # CAM_FRONT (cam_idx=0) ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        cam_name = "CAM_FRONT"
        cam_data = nusc.get('sample_data', first_sample_record['data'][cam_name])
        calib_data = nusc.get('calibrated_sensor', cam_data['calibrated_sensor_token'])
        
        # Extrinsics (camera to ego)
        extrinsics_cam_to_ego = np.eye(4)
        extrinsics_cam_to_ego[:3, :3] = Quaternion(calib_data['rotation']).rotation_matrix
        extrinsics_cam_to_ego[:3, 3] = np.array(calib_data['translation'])
        
        # Get ego pose (ego to world)
        ego_pose_data = nusc.get('ego_pose', cam_data['ego_pose_token'])
        ego_to_world = np.eye(4)
        ego_to_world[:3, :3] = Quaternion(ego_pose_data['rotation']).rotation_matrix
        ego_to_world[:3, 3] = np.array(ego_pose_data['translation'])
        
        # Transform camera extrinsics to world coordinates
        camera_front_start = ego_to_world @ extrinsics_cam_to_ego
        
        return camera_front_start
        
    except Exception as e:
        print(f"âš ï¸ NuScenes APIë¥¼ í†µí•œ ì¹´ë©”ë¼ í¬ì¦ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def transform_pose_to_world(translation: np.ndarray, rotation: np.ndarray, camera_front_start: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """obj_to_camera í¬ì¦ˆë¥¼ obj_to_world í¬ì¦ˆë¡œ ë³€í™˜"""
    # quaternionì„ rotation matrixë¡œ ë³€í™˜
    if len(rotation) == 4:  # quaternion [w, x, y, z]
        rot_matrix = R.from_quat([rotation[1], rotation[2], rotation[3], rotation[0]]).as_matrix()  # scipyëŠ” [x,y,z,w] ìˆœì„œ
    else:
        raise ValueError(f"Unsupported rotation format: {rotation}")
    
    # 4x4 ë³€í™˜ í–‰ë ¬ êµ¬ì„± (obj_to_camera)
    obj_to_camera = np.eye(4)
    obj_to_camera[:3, :3] = rot_matrix
    obj_to_camera[:3, 3] = translation
    
    # obj_to_world = camera_front_start @ obj_to_camera
    obj_to_world = camera_front_start @ obj_to_camera
    
    # world ì¢Œí‘œê³„ì—ì„œ translationê³¼ rotation ì¶”ì¶œ
    world_translation = obj_to_world[:3, 3]
    world_rotation_matrix = obj_to_world[:3, :3]
    
    world_rotation_quat = R.from_matrix(world_rotation_matrix).as_quat()  # [x, y, z, w]
    world_rotation_quat = np.array([world_rotation_quat[3], world_rotation_quat[0], world_rotation_quat[1], world_rotation_quat[2]])  # [w, x, y, z]
    
    return world_translation, world_rotation_quat

def extract_rigid_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: Optional[List[str]] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """RigidNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    rigid_quats = checkpoint['models']['RigidNodes']['instances_quats'].numpy() # (num_frames, num_instances, 4)
    rigid_trans = checkpoint['models']['RigidNodes']['instances_trans'].numpy() # (num_frames, num_instances, 3)
    rigid_sizes = checkpoint['models']['RigidNodes']['instances_size'].numpy()  # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = rigid_quats.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        instance_size = rigid_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]
        
        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = rigid_trans[frame_id, instance_id]
            rotation = rigid_quats[frame_id, instance_id]
            
            # translationì´ [0, 0, 0]ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if np.allclose(translation, [0, 0, 0], atol=1e-6):
                continue
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="car",
                detection_score=1.0,
                attribute_name="vehicle.moving",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='RigidNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def extract_smpl_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: Optional[List[str]] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """SMPLNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    smpl_instance_quats = checkpoint['models']['SMPLNodes']['instances_quats'].numpy()  # (num_frames, num_instances, 1, 4)
    smpl_instance_trans = checkpoint['models']['SMPLNodes']['instances_trans'].numpy()  # (num_frames, num_instances, 3)
    smpl_sizes = checkpoint['models']['SMPLNodes']['instances_size'].numpy()         # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = smpl_instance_trans.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        instance_size = smpl_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]

        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = smpl_instance_trans[frame_id, instance_id]
            rotation = smpl_instance_quats[frame_id, instance_id, 0]  # (1, 4) -> (4,)
            
            # translationì´ [0, 0, 0]ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if np.allclose(translation, [0, 0, 0], atol=1e-6):
                continue
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],  # SMPL ê´€ë ¨ ì†ì„±
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="pedestrian",
                detection_score=1.0,
                attribute_name="pedestrian.moving",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='SMPLNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def extract_deformable_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: Optional[List[str]] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """DeformableNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    deform_quats = checkpoint['models']['DeformableNodes']['instances_quats'].numpy()  # (num_frames, num_instances, 4)
    deform_trans = checkpoint['models']['DeformableNodes']['instances_trans'].numpy()  # (num_frames, num_instances, 3)
    deform_sizes = checkpoint['models']['DeformableNodes']['instances_size'].numpy()  # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = deform_quats.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        # ì¸ìŠ¤í„´ìŠ¤ë³„ í¬ê¸° ì •ë³´
        instance_size = deform_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]

        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = deform_trans[frame_id, instance_id]
            rotation = deform_quats[frame_id, instance_id]
            
            # translationì´ [0, 0, 0]ì¸ ê²½ìš° ê±´ë„ˆë›°ê¸°
            if np.allclose(translation, [0, 0, 0], atol=1e-6):
                continue
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="bicycle",
                detection_score=1.0,
                attribute_name="cycle.with_rider",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='DeformableNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def pose_annotation_to_dict(annotation: PoseAnnotation) -> OrderedDict:
    """PoseAnnotationì„ OrderedDictë¡œ ë³€í™˜ (NuScenes í¬ë§·)"""
    result = OrderedDict([
        ('token', annotation.token),
        ('sample_token', annotation.sample_token),
        ('instance_token', annotation.instance_token),
        ('visibility_token', annotation.visibility_token),
        ('attribute_tokens', annotation.attribute_tokens),
        ('translation', annotation.translation),
        ('size', annotation.size),
        ('rotation', annotation.rotation),
        ('prev', annotation.prev),
        ('next', annotation.next),
        ('num_lidar_pts', annotation.num_lidar_pts),
        ('num_radar_pts', annotation.num_radar_pts),
        ('velocity', annotation.velocity),
        ('detection_name', annotation.detection_name),
        ('detection_score', annotation.detection_score),
        ('attribute_name', annotation.attribute_name),
        # DriveStudio ì¶”ê°€ í•„ë“œ
        ('instance_id', annotation.instance_id),
        ('time_frame', annotation.time_frame),
        ('node_type', annotation.node_type),
        ('confidence', annotation.confidence),
        ('scene_token', annotation.scene_token),
        ('scene_name', annotation.scene_name)
    ])
    
    return result

def save_pose_annotations_to_json(annotations: List[PoseAnnotation], output_path: str) -> None:
    """í¬ì¦ˆ annotationì„ JSON íŒŒì¼ë¡œ ì €ì¥ (sample_tokenë³„ë¡œ ê·¸ë£¹í™”)"""
    # sample_tokenë³„ë¡œ ê·¸ë£¹í™”
    results = {}
    for annotation in annotations:
        sample_token = annotation.sample_token
        if sample_token not in results:
            results[sample_token] = []
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
        annotation_dict = pose_annotation_to_dict(annotation)
        results[sample_token].append(annotation_dict)
    
    # ìµœì¢… JSON êµ¬ì¡° ìƒì„±
    output_data = {
        "meta": {
            "use_camera": False,
            "use_lidar": True
        },
        "results": results
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_path, 'w') as f:
        json.dump(output_data, f, indent=2)

def analyze_checkpoint_structure(checkpoint: Dict[str, Any]) -> None:
    """ì²´í¬í¬ì¸íŠ¸ì˜ êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ë¶„ì„í•˜ê³  ì¶œë ¥"""
    print("=" * 50)
    print("CHECKPOINT STRUCTURE")
    print("=" * 50)
    
    for key, value in checkpoint.items():
        if isinstance(value, dict):
            print(f"{key}/ (dict with {len(value)} keys)")
            for sub_key, sub_value in value.items():
                if isinstance(sub_value, dict):
                    print(f"  {sub_key}/ (dict with {len(sub_value)} keys)")
                    for deep_key, deep_value in sub_value.items():
                        if hasattr(deep_value, 'shape'):
                            print(f"    {deep_key}: {list(deep_value.shape)} ({deep_value.dtype})")
                        else:
                            print(f"    {deep_key}: {type(deep_value).__name__}")
                elif hasattr(sub_value, 'shape'):
                    print(f"  {sub_key}: {list(sub_value.shape)} ({sub_value.dtype})")
                else:
                    print(f"  {sub_key}: {type(sub_value).__name__}")
        elif hasattr(value, 'shape'):
            print(f"{key}: {list(value.shape)} ({value.dtype})")
        else:
            print(f"{key}: {type(value).__name__}")
    print("=" * 50)

def check_checkpoint_structure(checkpoint: Dict[str, Any]) -> Dict[str, bool]:
    """ì²´í¬í¬ì¸íŠ¸ê°€ ì˜ˆìƒí•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸"""
    structure_check = {
        'has_models': False,
        'has_rigid_nodes': False,
        'has_smpl_nodes': False,
        'has_deformable_nodes': False
    }
    
    try:
        if 'models' in checkpoint:
            structure_check['has_models'] = True
            models = checkpoint['models']
            
            # RigidNodes í™•ì¸
            if ('RigidNodes' in models and 
                'instances_quats' in models['RigidNodes'] and 
                'instances_trans' in models['RigidNodes'] and
                'instances_size' in models['RigidNodes']):
                structure_check['has_rigid_nodes'] = True
            
            # SMPLNodes í™•ì¸
            if ('SMPLNodes' in models and 
                'instances_quats' in models['SMPLNodes'] and 
                'instances_trans' in models['SMPLNodes'] and
                'instances_size' in models['SMPLNodes']):
                structure_check['has_smpl_nodes'] = True
            
            # DeformableNodes í™•ì¸
            if ('DeformableNodes' in models and 
                'instances_quats' in models['DeformableNodes'] and 
                'instances_trans' in models['DeformableNodes'] and
                'instances_size' in models['DeformableNodes']):
                structure_check['has_deformable_nodes'] = True
                
    except Exception as e:
        print(f"Error checking structure: {e}")
    
    return structure_check

def process_folder_checkpoints(folder_path: str, checkpoint_filename: str = "checkpoint_final.pth", analyze_structure: bool = False, nuscenes_dataroot: Optional[str] = None, nuscenes_version: str = "v1.0-mini") -> None:
    """í´ë” ë‚´ ëª¨ë“  í•˜ìœ„ í´ë”ì˜ checkpoint íŒŒì¼ë“¤ì„ ì¼ê´„ ì²˜ë¦¬í•˜ì—¬ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ í†µí•©"""
    # scene ì´ë¦„ ë§¤í•‘ ë¦¬ìŠ¤íŠ¸
    scene_names = ['scene-0061', 'scene-0103', 'scene-0553', 'scene-0655', 'scene-0757', 
                   'scene-0796', 'scene-0916', 'scene-1077', 'scene-1094', 'scene-1100']
    
    folder_path_obj = Path(folder_path)
    
    if not folder_path_obj.exists():
        print(f"âŒ ì˜¤ë¥˜: í´ë” '{folder_path}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    if not folder_path_obj.is_dir():
        print(f"âŒ ì˜¤ë¥˜: '{folder_path}'ëŠ” í´ë”ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        return
    
    print(f"ğŸ” í´ë” '{folder_path}' ë‚´ì—ì„œ {checkpoint_filename} íŒŒì¼ë“¤ì„ ê²€ìƒ‰ì¤‘...")
    
    # í•˜ìœ„ í´ë”ë“¤ì—ì„œ checkpoint íŒŒì¼ ì°¾ê¸°
    checkpoint_pattern = str(folder_path_obj / "*" / checkpoint_filename)
    checkpoint_files = glob.glob(checkpoint_pattern)
    
    if not checkpoint_files:
        print(f"âŒ '{folder_path}' ë‚´ì—ì„œ {checkpoint_filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ì´ {len(checkpoint_files)}ê°œì˜ {checkpoint_filename} íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    for checkpoint_file in checkpoint_files:
        print(f"  - {checkpoint_file}")
    
    # ëª¨ë“  checkpointì—ì„œ ì¶”ì¶œí•œ annotationë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_combined_annotations = []
    
    # ê° checkpoint íŒŒì¼ ì²˜ë¦¬
    for i, checkpoint_file in enumerate(checkpoint_files):
        checkpoint_path = Path(checkpoint_file)
        parent_folder = checkpoint_path.parent
        folder_name = parent_folder.name
        
        print(f"\n{'='*80}")
        print(f"ì²˜ë¦¬ ì¤‘ ({i+1}/{len(checkpoint_files)}): {folder_name}")
        print(f"{'='*80}")
        
        # í´ë”ëª…ì—ì„œ scene ì¸ë±ìŠ¤ ì¶”ì¶œ
        import re
        scene_match = re.search(r'scene_(\d+)', folder_name)
        if scene_match:
            scene_index = int(scene_match.group(1))
            if scene_index < len(scene_names):
                scene_name = scene_names[scene_index]
                print(f"ğŸ“ í´ë” '{folder_name}'ì—ì„œ scene ì¸ë±ìŠ¤ {scene_index} ì¶”ì¶œ â†’ '{scene_name}'")
            else:
                print(f"âš ï¸ scene ì¸ë±ìŠ¤ {scene_index}ê°€ scene_names ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©.")
                scene_name = scene_names[0]  # ì²« ë²ˆì§¸ sceneì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        else:
            print(f"âš ï¸ í´ë”ëª… '{folder_name}'ì—ì„œ scene ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©.")
            scene_name = scene_names[0]  # ì²« ë²ˆì§¸ sceneì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        
        # NuScenes scene ì •ë³´ì™€ sample í† í° ê°€ì ¸ì˜¤ê¸°
        scene_token = ""
        sample_tokens = None
        camera_front_start = None
        
        if nuscenes_dataroot and scene_name:
            scene_token, scene_name, sample_tokens = get_nuscenes_scene_info(nuscenes_dataroot, scene_name, version=nuscenes_version)
            if sample_tokens:
                print(f"âœ… NuScenes scene '{scene_name}' ì •ë³´ ë¡œë“œ ì™„ë£Œ ({len(sample_tokens)}ê°œ sample)")
                
                # ì¹´ë©”ë¼ í¬ì¦ˆ ë³€í™˜ì„ ìœ„í•œ ì²« ë²ˆì§¸ ì¹´ë©”ë¼ í¬ì¦ˆ ë¡œë“œ
                camera_front_start = get_camera_front_start_pose(nuscenes_dataroot, scene_name, version=nuscenes_version)
                if camera_front_start is not None:
                    print(f"âœ… ì¹´ë©”ë¼ front start í¬ì¦ˆ ë¡œë“œ ì™„ë£Œ")
                else:
                    print(f"âš ï¸ ì¹´ë©”ë¼ front start í¬ì¦ˆ ë¡œë“œ ì‹¤íŒ¨ - ì¢Œí‘œ ë³€í™˜ ì—†ì´ ì§„í–‰")
            else:
                print(f"âŒ NuScenes scene '{scene_name}' ì •ë³´ ë¡œë“œ ì‹¤íŒ¨ - ì´ checkpoint ê±´ë„ˆë›°ê¸°")
                continue
        else:
            print(f"âŒ NuScenes ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ - ì´ checkpoint ê±´ë„ˆë›°ê¸°")
            continue
        
        try:
            # checkpoint ë¡œë“œ
            print(f"Loading checkpoint from {checkpoint_path}...")
            checkpoint = torch.load(str(checkpoint_path), map_location='cpu')
            
            # ë¡œë“œëœ ë°ì´í„° íƒ€ì… í™•ì¸
            if not isinstance(checkpoint, dict):
                print(f"âŒ Error: Expected dict, but got {type(checkpoint)}")
                continue
            
            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ë¶„ì„ (ì˜µì…˜)
            if analyze_structure:
                print("\nğŸ” Analyzing checkpoint structure...")
                analyze_checkpoint_structure(checkpoint)
                print()
            
            # êµ¬ì¡° ê²€ì¦
            structure_check = check_checkpoint_structure(checkpoint)
            
            if not structure_check['has_models']:
                print("âŒ Error: No 'models' key found in checkpoint. Skipping.")
                continue
            
            # ê° ë…¸ë“œ íƒ€ì…ë³„ë¡œ í¬ì¦ˆ ì¶”ì¶œ
            checkpoint_annotations = []
            
            if structure_check['has_rigid_nodes']:
                print("Extracting RigidNodes poses...")
                rigid_annotations = extract_rigid_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
                checkpoint_annotations.extend(rigid_annotations)
                print(f"âœ… Extracted {len(rigid_annotations)} RigidNodes annotations")
            
            if structure_check['has_smpl_nodes']:
                print("Extracting SMPLNodes poses...")
                smpl_annotations = extract_smpl_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
                checkpoint_annotations.extend(smpl_annotations)
                print(f"âœ… Extracted {len(smpl_annotations)} SMPLNodes annotations")
            
            if structure_check['has_deformable_nodes']:
                print("Extracting DeformableNodes poses...")
                deform_annotations = extract_deformable_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
                checkpoint_annotations.extend(deform_annotations)
                print(f"âœ… Extracted {len(deform_annotations)} DeformableNodes annotations")
            
            # í˜„ì¬ checkpointì˜ annotationë“¤ì„ ì „ì²´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_combined_annotations.extend(checkpoint_annotations)
            print(f"âœ… ì™„ë£Œ: {folder_name} ({len(checkpoint_annotations)} annotations)")
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ ({folder_name}): {e}")
            continue
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥
    if all_combined_annotations:
        output_file = folder_path_obj / "poses.json"
        save_pose_annotations_to_json(all_combined_annotations, str(output_file))
        print(f"\nğŸ‰ ëª¨ë“  checkpoint íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"âœ… ì´ {len(all_combined_annotations)}ê°œì˜ annotationì„ '{output_file}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print(f"ì²˜ë¦¬ëœ checkpoint íŒŒì¼: {len(checkpoint_files)}ê°œ")
    else:
        print(f"\nâš ï¸ ì¶”ì¶œëœ í¬ì¦ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser(description="Extract pose data from DriveStudio checkpoints")
    
    # í´ë” ì¼ê´„ ì²˜ë¦¬ ì˜µì…˜
    parser.add_argument("--folder", type=str,
                        default="/workspace/drivestudio/output/feasibility_check/updated",
                        help="Path to folder containing subfolders with checkpoint files")
    parser.add_argument("--checkpoint-filename", type=str, 
                       default="checkpoint_final.pth",
                       help="Name of checkpoint file to search for (default: checkpoint_final.pth)")
    parser.add_argument("--analyze-structure", type=bool, 
                       default=False,
                       help="Analyze and print checkpoint structure for each file")
    
    # ê³µí†µ ì˜µì…˜ë“¤
    parser.add_argument("--nuscenes-dataroot", type=str, 
                        default="/workspace/drivestudio/data/nuscenes/raw",
                        help="NuScenes ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (í‚¤í”„ë ˆì„ ë§¤í•‘ìš©)")
    parser.add_argument("--nuscenes-version", type=str, 
                        default="v1.0-mini",
                        help="NuScenes ë²„ì „ (ì˜ˆ: 'v1.0-mini', 'v1.0-trainval')")
    
    args = parser.parse_args()
    
    # í´ë” ì¼ê´„ ì²˜ë¦¬
    print(f"ğŸš€ í´ë” ì¼ê´„ ì²˜ë¦¬ ëª¨ë“œ")
    print(f"ğŸ“ ëŒ€ìƒ í´ë”: {args.folder}")
    print(f"ğŸ“„ ê²€ìƒ‰í•  íŒŒì¼ëª…: {args.checkpoint_filename}")
    if args.analyze_structure:
        print(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ë¶„ì„: í™œì„±í™”")
    process_folder_checkpoints(
        folder_path=args.folder,
        checkpoint_filename=args.checkpoint_filename,
        analyze_structure=args.analyze_structure,
        nuscenes_dataroot=args.nuscenes_dataroot,
        nuscenes_version=args.nuscenes_version
    )

if __name__ == "__main__":
    main()
