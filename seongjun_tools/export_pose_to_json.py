import torch
import numpy as np
import json
import os
from collections import OrderedDict
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import argparse
from nuscenes.nuscenes import NuScenes
from scipy.spatial.transform import Rotation as R
from pyquaternion import Quaternion

@dataclass
class PoseAnnotation:
    """DriveStudio í¬ì¦ˆ ë°ì´í„°ë¥¼ NuScenes annotation í¬ë§·ìœ¼ë¡œ ì €ì¥í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤"""
    token: str                           # ê³ ìœ  í† í°
    sample_token: str                    # ìƒ˜í”Œ í† í° (NuScenes í‚¤í”„ë ˆì„ê³¼ ë§¤ì¹­)
    instance_token: str                  # ì¸ìŠ¤í„´ìŠ¤ í† í°
    visibility_token: str                # ê°€ì‹œì„± í† í° (ê¸°ë³¸ê°’ "4")
    attribute_tokens: List[str]          # ì†ì„± í† í°ë“¤
    translation: List[float]             # [x, y, z]
    size: List[float]                   # [w, l, h]
    rotation: List[float]               # quaternion [w, x, y, z]
    prev: str                           # ì´ì „ annotation í† í°
    next: str                           # ë‹¤ìŒ annotation í† í°
    num_lidar_pts: int                  # ë¼ì´ë‹¤ í¬ì¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’ 0)
    num_radar_pts: int                  # ë ˆì´ë” í¬ì¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’ 0)
    velocity: List[float]               # [vx, vy] ì†ë„
    detection_name: str                 # íƒì§€ ê°ì²´ ì´ë¦„
    detection_score: float              # íƒì§€ ì ìˆ˜
    attribute_name: str                 # ì†ì„± ì´ë¦„
    
    # DriveStudio ì¶”ê°€ ì •ë³´
    instance_id: int                    # ì¸ìŠ¤í„´ìŠ¤ ID (0~190)
    time_frame: int                     # ì‹œê°„ í”„ë ˆì„
    node_type: str                      # 'RigidNodes', 'SMPLNodes', 'DeformableNodes'
    confidence: float = 1.0             # ì‹ ë¢°ë„
    scene_token: str = ""               # NuScenes scene í† í°
    scene_name: str = ""                # NuScenes scene ì´ë¦„

def get_nuscenes_scene_info(dataroot: str, scene_name: str, version: str = 'v1.0-mini') -> Tuple[str, str, List[str]]:
    """NuScenes scene ì´ë¦„ìœ¼ë¡œ scene ì •ë³´ì™€ sample í† í°ë“¤ì„ ê°€ì ¸ì˜´"""
    try:
        nusc = NuScenes(version=version, dataroot=dataroot, verbose=False)
        
        # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
        scene = None
        for s in nusc.scene:
            if s['name'] == scene_name:
                scene = s
                break
                
        if scene is None:
            print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "", "", []
            
        # sceneì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œë¶€í„° ì‹œì‘
        sample = nusc.get('sample', scene['first_sample_token'])
        sample_tokens = []
        
        while True:
            sample_tokens.append(sample['token'])
            if sample['next'] == '':
                break
            sample = nusc.get('sample', sample['next'])
            
        return scene['token'], scene['name'], sample_tokens
        
    except Exception as e:
        print(f"âš ï¸ NuScenes scene ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return "", "", []

def get_camera_front_start_pose(nuscenes_dataroot: str, scene_name: str, version: str = 'v1.0-mini') -> Optional[np.ndarray]:
    """NuScenes ì²« ë²ˆì§¸ ì¹´ë©”ë¼ í¬ì¦ˆë¥¼ ê°€ì ¸ì˜´ (ì¢Œí‘œ ì •ë ¬ìš©)"""
    try:
        # NuScenes API ì´ˆê¸°í™”
        nusc = NuScenes(version=version, dataroot=nuscenes_dataroot, verbose=False)
        
        # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
        scene = None
        for s in nusc.scene:
            if s['name'] == scene_name:
                scene = s
                break
                
        if scene is None:
            print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # ì²« ë²ˆì§¸ sample ê°€ì ¸ì˜¤ê¸°
        first_sample_token = scene['first_sample_token']
        first_sample_record = nusc.get('sample', first_sample_token)
        
        # CAM_FRONT (cam_idx=0) ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        cam_name = "CAM_FRONT"
        cam_data = nusc.get('sample_data', first_sample_record['data'][cam_name])
        calib_data = nusc.get('calibrated_sensor', cam_data['calibrated_sensor_token'])
        
        # Extrinsics (camera to ego)
        extrinsics_cam_to_ego = np.eye(4)
        extrinsics_cam_to_ego[:3, :3] = Quaternion(calib_data['rotation']).rotation_matrix
        extrinsics_cam_to_ego[:3, 3] = np.array(calib_data['translation'])
        
        # Get ego pose (ego to world)
        ego_pose_data = nusc.get('ego_pose', cam_data['ego_pose_token'])
        ego_to_world = np.eye(4)
        ego_to_world[:3, :3] = Quaternion(ego_pose_data['rotation']).rotation_matrix
        ego_to_world[:3, 3] = np.array(ego_pose_data['translation'])
        
        # Transform camera extrinsics to world coordinates
        camera_front_start = ego_to_world @ extrinsics_cam_to_ego
        
        return camera_front_start
        
    except Exception as e:
        print(f"âš ï¸ NuScenes APIë¥¼ í†µí•œ ì¹´ë©”ë¼ í¬ì¦ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def transform_pose_to_world(translation: np.ndarray, rotation: np.ndarray, camera_front_start: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """obj_to_camera í¬ì¦ˆë¥¼ obj_to_world í¬ì¦ˆë¡œ ë³€í™˜"""
    # quaternionì„ rotation matrixë¡œ ë³€í™˜
    if len(rotation) == 4:  # quaternion [w, x, y, z]
        rot_matrix = R.from_quat([rotation[1], rotation[2], rotation[3], rotation[0]]).as_matrix()  # scipyëŠ” [x,y,z,w] ìˆœì„œ
    else:
        raise ValueError(f"Unsupported rotation format: {rotation}")
    
    # 4x4 ë³€í™˜ í–‰ë ¬ êµ¬ì„± (obj_to_camera)
    obj_to_camera = np.eye(4)
    obj_to_camera[:3, :3] = rot_matrix
    obj_to_camera[:3, 3] = translation
    
    # obj_to_world = camera_front_start @ obj_to_camera
    obj_to_world = camera_front_start @ obj_to_camera
    
    # world ì¢Œí‘œê³„ì—ì„œ translationê³¼ rotation ì¶”ì¶œ
    world_translation = obj_to_world[:3, 3]
    world_rotation_matrix = obj_to_world[:3, :3]
    
    # yaw íšŒì „ ì ìš© (Zì¶• ê¸°ì¤€)
    angle_deg = 0
    angle_rad = np.deg2rad(angle_deg)
    yaw_rotation = np.array([
        [np.cos(angle_rad), -np.sin(angle_rad), 0],
        [np.sin(angle_rad), np.cos(angle_rad), 0],
        [0, 0, 1]
    ])
    world_rotation_matrix = yaw_rotation @ world_rotation_matrix
    
    world_rotation_quat = R.from_matrix(world_rotation_matrix).as_quat()  # [x, y, z, w]
    world_rotation_quat = np.array([world_rotation_quat[3], world_rotation_quat[0], world_rotation_quat[1], world_rotation_quat[2]])  # [w, x, y, z]
    
    return world_translation, world_rotation_quat

def extract_rigid_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: List[str] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """RigidNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    rigid_quats = checkpoint['models']['RigidNodes']['instances_quats'].numpy() # (num_frames, num_instances, 4)
    rigid_trans = checkpoint['models']['RigidNodes']['instances_trans'].numpy() # (num_frames, num_instances, 3)
    rigid_sizes = checkpoint['models']['RigidNodes']['instances_size'].numpy()  # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = rigid_quats.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        instance_size = rigid_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]
        
        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = rigid_trans[frame_id, instance_id]
            rotation = rigid_quats[frame_id, instance_id]
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="car",
                detection_score=1.0,
                attribute_name="vehicle.moving",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='RigidNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def extract_smpl_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: List[str] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """SMPLNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    smpl_instance_quats = checkpoint['models']['SMPLNodes']['instances_quats'].numpy()  # (num_frames, num_instances, 1, 4)
    smpl_instance_trans = checkpoint['models']['SMPLNodes']['instances_trans'].numpy()  # (num_frames, num_instances, 3)
    smpl_sizes = checkpoint['models']['SMPLNodes']['instances_size'].numpy()         # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = smpl_instance_trans.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        instance_size = smpl_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]

        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = smpl_instance_trans[frame_id, instance_id]
            rotation = smpl_instance_quats[frame_id, instance_id, 0]  # (1, 4) -> (4,)
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],  # SMPL ê´€ë ¨ ì†ì„±
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="pedestrian",
                detection_score=1.0,
                attribute_name="pedestrian.moving",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='SMPLNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def extract_deformable_nodes_poses(checkpoint: Dict[str, Any], scene_token: str, scene_name: str, sample_tokens: List[str] = None, camera_front_start: Optional[np.ndarray] = None) -> List[PoseAnnotation]:
    """DeformableNodes í¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ (5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ)"""
    deform_quats = checkpoint['models']['DeformableNodes']['instances_quats'].numpy()  # (num_frames, num_instances, 4)
    deform_trans = checkpoint['models']['DeformableNodes']['instances_trans'].numpy()  # (num_frames, num_instances, 3)
    deform_sizes = checkpoint['models']['DeformableNodes']['instances_size'].numpy()  # (num_instances, 3)
    
    annotations = []
    num_frames, num_instances = deform_quats.shape[:2]
    
    # 5ì˜ ë°°ìˆ˜ í”„ë ˆì„ë§Œ ì²˜ë¦¬
    keyframe_indices = [i for i in range(0, num_frames, 5)]
    
    # sample_tokensê°€ ì œê³µëœ ê²½ìš° ê°œìˆ˜ í™•ì¸
    if sample_tokens and len(sample_tokens) != len(keyframe_indices):
        print(f"âš ï¸ ê²½ê³ : NuScenes sample ìˆ˜({len(sample_tokens)})ì™€ í‚¤í”„ë ˆì„ ìˆ˜({len(keyframe_indices)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    for instance_id in range(num_instances):
        # ì¸ìŠ¤í„´ìŠ¤ë³„ í¬ê¸° ì •ë³´
        instance_size = deform_sizes[instance_id].tolist()
        instance_size = [instance_size[1], instance_size[0], instance_size[2]]

        for idx, frame_id in enumerate(keyframe_indices):
            sample_token = sample_tokens[idx] if sample_tokens and idx < len(sample_tokens) else ""
            
            translation = deform_trans[frame_id, instance_id]
            rotation = deform_quats[frame_id, instance_id]
            
            # camera ì¢Œí‘œê³„ì—ì„œ world ì¢Œí‘œê³„ë¡œ ë³€í™˜
            if camera_front_start is not None:
                translation, rotation = transform_pose_to_world(translation, rotation, camera_front_start)
            
            translation = translation.tolist()
            rotation = rotation.tolist()
            
            annotation = PoseAnnotation(
                token="",
                sample_token=sample_token,
                instance_token="",
                visibility_token="",
                attribute_tokens=[],
                translation=translation,
                size=instance_size,
                rotation=rotation,
                prev="",
                next="",
                num_lidar_pts=0,
                num_radar_pts=0,
                velocity=[0.0, 0.0],
                detection_name="bicycle",
                detection_score=1.0,
                attribute_name="cycle.with_rider",
                instance_id=instance_id,
                time_frame=frame_id,
                node_type='DeformableNodes',
                confidence=1.0,
                scene_token=scene_token,
                scene_name=scene_name
            )
            annotations.append(annotation)
    
    return annotations

def pose_annotation_to_dict(annotation: PoseAnnotation) -> OrderedDict:
    """PoseAnnotationì„ OrderedDictë¡œ ë³€í™˜ (NuScenes í¬ë§·)"""
    result = OrderedDict([
        ('token', annotation.token),
        ('sample_token', annotation.sample_token),
        ('instance_token', annotation.instance_token),
        ('visibility_token', annotation.visibility_token),
        ('attribute_tokens', annotation.attribute_tokens),
        ('translation', annotation.translation),
        ('size', annotation.size),
        ('rotation', annotation.rotation),
        ('prev', annotation.prev),
        ('next', annotation.next),
        ('num_lidar_pts', annotation.num_lidar_pts),
        ('num_radar_pts', annotation.num_radar_pts),
        ('velocity', annotation.velocity),
        ('detection_name', annotation.detection_name),
        ('detection_score', annotation.detection_score),
        ('attribute_name', annotation.attribute_name),
        # DriveStudio ì¶”ê°€ í•„ë“œ
        ('instance_id', annotation.instance_id),
        ('time_frame', annotation.time_frame),
        ('node_type', annotation.node_type),
        ('confidence', annotation.confidence),
        ('scene_token', annotation.scene_token),
        ('scene_name', annotation.scene_name)
    ])
    
    return result

def save_pose_annotations_to_json(annotations: List[PoseAnnotation], output_path: str) -> None:
    """í¬ì¦ˆ annotationì„ JSON íŒŒì¼ë¡œ ì €ì¥ (sample_tokenë³„ë¡œ ê·¸ë£¹í™”)"""
    # sample_tokenë³„ë¡œ ê·¸ë£¹í™”
    results = {}
    for annotation in annotations:
        sample_token = annotation.sample_token
        if sample_token not in results:
            results[sample_token] = []
        
        # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
        annotation_dict = pose_annotation_to_dict(annotation)
        results[sample_token].append(annotation_dict)
    
    # ìµœì¢… JSON êµ¬ì¡° ìƒì„±
    output_data = {
        "meta": {
            "use_camera": False,
            "use_lidar": True
        },
        "results": results
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open(output_path, 'w') as f:
        json.dump(output_data, f, indent=2)

def analyze_checkpoint_structure(checkpoint: Dict[str, Any]) -> None:
    """ì²´í¬í¬ì¸íŠ¸ì˜ êµ¬ì¡°ë¥¼ ê°„ë‹¨íˆ ë¶„ì„í•˜ê³  ì¶œë ¥"""
    print("=" * 50)
    print("CHECKPOINT STRUCTURE")
    print("=" * 50)
    
    for key, value in checkpoint.items():
        if isinstance(value, dict):
            print(f"{key}/ (dict with {len(value)} keys)")
            for sub_key, sub_value in value.items():
                if isinstance(sub_value, dict):
                    print(f"  {sub_key}/ (dict with {len(sub_value)} keys)")
                    for deep_key, deep_value in sub_value.items():
                        if hasattr(deep_value, 'shape'):
                            print(f"    {deep_key}: {list(deep_value.shape)} ({deep_value.dtype})")
                        else:
                            print(f"    {deep_key}: {type(deep_value).__name__}")
                elif hasattr(sub_value, 'shape'):
                    print(f"  {sub_key}: {list(sub_value.shape)} ({sub_value.dtype})")
                else:
                    print(f"  {sub_key}: {type(sub_value).__name__}")
        elif hasattr(value, 'shape'):
            print(f"{key}: {list(value.shape)} ({value.dtype})")
        else:
            print(f"{key}: {type(value).__name__}")
    print("=" * 50)

def check_checkpoint_structure(checkpoint: Dict[str, Any]) -> Dict[str, bool]:
    """ì²´í¬í¬ì¸íŠ¸ê°€ ì˜ˆìƒí•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ í™•ì¸"""
    structure_check = {
        'has_models': False,
        'has_rigid_nodes': False,
        'has_smpl_nodes': False,
        'has_deformable_nodes': False
    }
    
    try:
        if 'models' in checkpoint:
            structure_check['has_models'] = True
            models = checkpoint['models']
            
            # RigidNodes í™•ì¸
            if ('RigidNodes' in models and 
                'instances_quats' in models['RigidNodes'] and 
                'instances_trans' in models['RigidNodes'] and
                'instances_size' in models['RigidNodes']):
                structure_check['has_rigid_nodes'] = True
            
            # SMPLNodes í™•ì¸
            if ('SMPLNodes' in models and 
                'instances_quats' in models['SMPLNodes'] and 
                'instances_trans' in models['SMPLNodes'] and
                'instances_size' in models['SMPLNodes']):
                structure_check['has_smpl_nodes'] = True
            
            # DeformableNodes í™•ì¸
            if ('DeformableNodes' in models and 
                'instances_quats' in models['DeformableNodes'] and 
                'instances_trans' in models['DeformableNodes'] and
                'instances_size' in models['DeformableNodes']):
                structure_check['has_deformable_nodes'] = True
                
    except Exception as e:
        print(f"Error checking structure: {e}")
    
    return structure_check

def extract_all_poses_from_checkpoint(checkpoint_path: str, output_dir: str, nuscenes_dataroot: Optional[str] = None, scene_name: str = "", nuscenes_version: str = "v1.0-mini") -> None:
    """checkpointì—ì„œ ëª¨ë“  í¬ì¦ˆ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ JSONìœ¼ë¡œ ì €ì¥"""
    print(f"Loading checkpoint from {checkpoint_path}...")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # ë¡œë“œëœ ë°ì´í„° íƒ€ì… í™•ì¸
    print(f"Loaded data type: {type(checkpoint)}")
    
    if not isinstance(checkpoint, dict):
        print(f"âŒ Error: Expected dict, but got {type(checkpoint)}")
        print("Cannot process non-dictionary checkpoint files.")
        return

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # NuScenes scene ì •ë³´ì™€ sample í† í° ê°€ì ¸ì˜¤ê¸°
    scene_token = ""
    sample_tokens = None
    camera_front_start = None
    
    if nuscenes_dataroot and scene_name:
        scene_token, scene_name, sample_tokens = get_nuscenes_scene_info(nuscenes_dataroot, scene_name, version=nuscenes_version)
        if sample_tokens:
            print(f"âœ… NuScenes scene '{scene_name}' ì •ë³´ ë¡œë“œ ì™„ë£Œ")
            print(f"âœ… NuScenes sample í† í° ë¡œë“œ ì™„ë£Œ ({len(sample_tokens)}ê°œ)")
            
            # ì¹´ë©”ë¼ í¬ì¦ˆ ë³€í™˜ì„ ìœ„í•œ ì²« ë²ˆì§¸ ì¹´ë©”ë¼ í¬ì¦ˆ ë¡œë“œ
            camera_front_start = get_camera_front_start_pose(nuscenes_dataroot, scene_name, version=nuscenes_version)
            if camera_front_start is not None:
                print(f"âœ… ì¹´ë©”ë¼ front start í¬ì¦ˆ ë¡œë“œ ì™„ë£Œ (ì¢Œí‘œ ë³€í™˜ìš©)")
            else:
                print(f"âš ï¸ ì¹´ë©”ë¼ front start í¬ì¦ˆ ë¡œë“œ ì‹¤íŒ¨ - ì¢Œí‘œ ë³€í™˜ ì—†ì´ ì§„í–‰")
        else:
            print(f"âŒ ê²½ë¡œ: '{nuscenes_dataroot}'ì—ì„œ NuScenes scene '{scene_name}' ì •ë³´ ë¡œë“œ ì‹¤íŒ¨")
            return
    else:
        print(f"âŒ ê²½ë¡œ: '{nuscenes_dataroot}'ì—ì„œ NuScenes scene '{scene_name}' ì •ë³´ ë¡œë“œ ì‹¤íŒ¨")
        return

    # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ë¶„ì„
    print("\nğŸ” Analyzing checkpoint structure...")
    analyze_checkpoint_structure(checkpoint)
    print()
        
    # êµ¬ì¡° ê²€ì¦
    print("ğŸ” Checking required structure...")
    structure_check = check_checkpoint_structure(checkpoint)
    
    for key, value in structure_check.items():
        status = "âœ…" if value else "âŒ"
        print(f"{status} {key}: {value}")
    
    if not structure_check['has_models']:
        print("âŒ Error: No 'models' key found in checkpoint. Cannot extract poses.")
        return
    
    print()
       
    # ê° ë…¸ë“œ íƒ€ì…ë³„ë¡œ í¬ì¦ˆ ì¶”ì¶œ
    all_annotations = []
    
    if structure_check['has_rigid_nodes']:
        print("Extracting RigidNodes poses...")
        try:
            rigid_annotations = extract_rigid_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
            rigid_output = output_path / "rigid_nodes_poses.json"
            save_pose_annotations_to_json(rigid_annotations, str(rigid_output))
            print(f"âœ… Saved {len(rigid_annotations)} RigidNodes annotations to {rigid_output}")
            all_annotations.extend(rigid_annotations)
        except Exception as e:
            print(f"âŒ Error extracting RigidNodes: {e}")
    else:
        print("â­ï¸ Skipping RigidNodes (not found in checkpoint)")
    
    if structure_check['has_smpl_nodes']:
        print("Extracting SMPLNodes poses...")
        try:
            smpl_annotations = extract_smpl_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
            smpl_output = output_path / "smpl_nodes_poses.json"
            save_pose_annotations_to_json(smpl_annotations, str(smpl_output))
            print(f"âœ… Saved {len(smpl_annotations)} SMPLNodes annotations to {smpl_output}")
            all_annotations.extend(smpl_annotations)
        except Exception as e:
            print(f"âŒ Error extracting SMPLNodes: {e}")
    else:
        print("â­ï¸ Skipping SMPLNodes (not found in checkpoint)")
    
    if structure_check['has_deformable_nodes']:
        print("Extracting DeformableNodes poses...")
        try:
            deform_annotations = extract_deformable_nodes_poses(checkpoint, scene_token, scene_name, sample_tokens, camera_front_start)
            deform_output = output_path / "deformable_nodes_poses.json"
            save_pose_annotations_to_json(deform_annotations, str(deform_output))
            print(f"âœ… Saved {len(deform_annotations)} DeformableNodes annotations to {deform_output}")
            all_annotations.extend(deform_annotations)
        except Exception as e:
            print(f"âŒ Error extracting DeformableNodes: {e}")
    else:
        print("â­ï¸ Skipping DeformableNodes (not found in checkpoint)")
    
    # ì¶”ì¶œëœ í¬ì¦ˆê°€ ìˆìœ¼ë©´ í†µí•© íŒŒì¼ ìƒì„±
    if all_annotations:
        print("Combining all poses...")
        all_output = output_path / "all_poses.json"
        save_pose_annotations_to_json(all_annotations, str(all_output))
        print(f"âœ… Saved {len(all_annotations)} total annotations to {all_output}")
    else:
        print("âš ï¸ No pose data extracted from checkpoint")
    
    print("Pose extraction completed!")

def main():
    parser = argparse.ArgumentParser(description="Extract pose data from DriveStudio checkpoint")
    parser.add_argument("--checkpoint", type=str, default="/workspace/drivestudio/output/feasibility_check/run_original_scene_0_date_0529_try_1/checkpoint_final.pth", 
                       help="Path to checkpoint file")
    parser.add_argument("--output", type=str, default=None, 
                       help="Output directory for JSON files (default: checkpoint ê²½ë¡œì˜ keyframe_instance_poses_data í´ë”)")
    parser.add_argument("--nuscenes-dataroot", type=str, default="/workspace/drivestudio/data/nuscenes/raw",
                       help="NuScenes ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (í‚¤í”„ë ˆì„ ë§¤í•‘ìš©)")
    parser.add_argument("--scene-name", type=str, default="scene-0061",
                       help="NuScenes scene ì´ë¦„ (ì˜ˆ: 'scene-0061')")
    parser.add_argument("--nuscenes-version", type=str, default="v1.0-mini",
                       help="NuScenes ë²„ì „ (ì˜ˆ: 'v1.0-mini', 'v1.0-trainval')")
    
    args = parser.parse_args()
    
    # outputì´ ì§€ì •ë˜ì§€ ì•Šì€ ê²½ìš° checkpoint ê²½ë¡œ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •
    if args.output is None:
        checkpoint_path = Path(args.checkpoint)
        args.output = str(checkpoint_path.parent / "keyframe_instance_poses_data")
    
    extract_all_poses_from_checkpoint(args.checkpoint, args.output, args.nuscenes_dataroot, args.scene_name, args.nuscenes_version)

if __name__ == "__main__":
    main()
