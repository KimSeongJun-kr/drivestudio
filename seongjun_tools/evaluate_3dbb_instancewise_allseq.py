import argparse
import copy
import numpy as np
import tqdm
from typing import List, Dict, Optional
from collections import defaultdict
from dataclasses import dataclass
import json
import os
import glob
import pandas as pd
from pathlib import Path
import re
from typing import Callable, Tuple

from nuscenes import NuScenes
from nuscenes.eval.detection.config import config_factory
from nuscenes.eval.detection.algo import calc_ap
from nuscenes.eval.detection.constants import TP_METRICS
# from nuscenes.eval.tracking.data_classes import TrackingBox
from nuscenes.eval.common.data_classes import EvalBoxes
from nuscenes.eval.common.utils import center_distance, scale_iou, yaw_diff, velocity_l2, attr_acc, cummean



# Import functions from other modules
import sys
sys.path.append('/workspace/drivestudio')
from seongjun_tools.generate_selected_instances import filter_boxes_by_common_scenes
from seongjun_tools.evaluate_3dbb import filter_eval_boxes, filter_boxes_by_scene
from seongjun_tools.utils.detection.data_classes import DetectionBox, DetectionMetricDataList, DetectionMetrics, DetectionMetricData
from seongjun_tools.utils.loaders import load_gt, load_prediction, add_center_dist
from seongjun_tools.utils.splits import create_splits_scenes
from seongjun_tools.evaluate_3dbb_instancewise import perform_evaluation, match_boxes, _get_scene_sample_tokens_chronologically, extract_all_boxes_from_json, find_files_with_name, parse_metrics_json
from datasets.nuscenes.nuscenes_sourceloader import OBJECT_CLASS_NODE_MAPPING
from datasets.base.scene_dataset import ModelType

detection_mapping = {
    'movable_object.barrier': 'barrier',
    'vehicle.bicycle': 'bicycle',
    'vehicle.bus.bendy': 'bus',
    'vehicle.bus.rigid': 'bus',
    'vehicle.car': 'car',
    'vehicle.construction': 'construction_vehicle',
    'vehicle.motorcycle': 'motorcycle',
    'human.pedestrian.adult': 'pedestrian',
    'human.pedestrian.child': 'pedestrian',
    'human.pedestrian.construction_worker': 'pedestrian',
    'human.pedestrian.police_officer': 'pedestrian',
    'movable_object.trafficcone': 'traffic_cone',
    'vehicle.trailer': 'trailer',
    'vehicle.truck': 'truck'
}
detection_mapping_inv = {v: k for k, v in detection_mapping.items()}

def extract_boxes_from_json_to_evalboxes_multiple(nusc, target_file_scene_pairs: List[Tuple[str, str]]) -> EvalBoxes:
    """JSON íŒŒì¼ì—ì„œ ë°•ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ EvalBoxes í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        json_path: JSON íŒŒì¼ ê²½ë¡œ
        multi_scenes: ì‚¬ìš©í•  scene ë¦¬ìŠ¤íŠ¸
        
    Returns:
        EvalBoxes ê°ì²´
    """
    eval_boxes = EvalBoxes()

    for target_file, scene_name in target_file_scene_pairs:
        frame_boxes = extract_all_boxes_from_json(target_file)
        if frame_boxes is None:
            print(f"âŒ JSON íŒŒì¼ì—ì„œ ë°•ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target_file}")
            return EvalBoxes()
        
        sample_tokens = _get_scene_sample_tokens_chronologically(nusc, scene_name)

        # sample_tokensì™€ frame_id ë§¤í•‘ (ìˆœì„œëŒ€ë¡œ ë§¤ì¹­)
        for kf_id, sample_token in enumerate(sample_tokens):
            f_id = kf_id * 5
            if f_id in frame_boxes:
                boxes = frame_boxes[f_id]
                detection_boxes = []
                
                for box in boxes:
                    try:
                        # boxê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
                        if not isinstance(box, dict):
                            print(f"âŒ ë°•ìŠ¤ ì •ë³´ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(box)}")
                            continue
                        detection_name = box.get('detection_name', '')
                        if detection_name == 'human.pedestrian.personal_mobility':
                            continue

                        # box ì •ë³´ë¥¼ DetectionBoxë¡œ ë³€í™˜
                        detection_box = DetectionBox(
                            sample_token=sample_token,
                            translation=box.get('translation', [0, 0, 0]),
                            size=box.get('size', [1, 1, 1]),
                            rotation=box.get('rotation', [1, 0, 0, 0]),
                            velocity=box.get('velocity', [0, 0]),
                            detection_name=detection_name,
                            detection_score=box.get('detection_score', 0.5),
                            attribute_name=box.get('attribute_name', ''),
                            instance_token=box.get('instance_token', ''),
                            instance_idx=box.get('instance_idx', -1),
                            num_gaussians=box.get('num_gaussians', -1)
                        )
                        detection_boxes.append(detection_box)
                    except Exception as e:
                        print(f"âŒ ë°•ìŠ¤ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        print(f"   ë°•ìŠ¤ ì •ë³´: {box}")
                        continue
                
                if detection_boxes:
                    eval_boxes.add_boxes(sample_token, detection_boxes)
    
    return eval_boxes

def main() -> None:
    parser = argparse.ArgumentParser(
        description="Multi-file 3D bounding box evaluation")
    parser.add_argument(
        "--gt",
        type=str,
        default=None,
        help="Path to ground truth prediction json file",
    )
    parser.add_argument(
        "--ctrl",
        type=str,
        default='/workspace/drivestudio/data/nuscenes/raw/v1.0-mini/boxes_noise_bias.json',
        # default='/workspace/drivestudio/data/nuscenes/raw/v1.0-mini/boxes_centerpoint.json',
        help="Path to comparison prediction json file",
    )
    parser.add_argument(
        "--tar",
        type=str,
        default='/workspace/drivestudio/output/box_experiments_0910',
        help="Directory to search for target files",
    )
    parser.add_argument(
        "--name",
        type=str,
        default='box_poses_50000.json',
        help="Name of the files to find in tar directory",
    )
    parser.add_argument(
        "--version",
        type=str,
        default="v1.0-mini",
        help="NuScenes version",
    )
    parser.add_argument(
        "--dataroot",
        type=str,
        default="/workspace/drivestudio/data/nuscenes/raw",
        help="NuScenes dataroot",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Output CSV file path",
    )
    parser.add_argument(
        "--verbose",
        type=bool,
        default=True,
        help="Verbose",
    )
    args = parser.parse_args()

    # Verify input files exist
    if args.gt is not None:
        assert os.path.exists(args.gt), f'Error: GT file does not exist: {args.gt}'
    if args.ctrl is not None:
        assert os.path.exists(args.ctrl), f'Error: Compare file does not exist: {args.ctrl}'
    if args.tar is not None:
        assert os.path.exists(args.tar), f'Error: Tar directory does not exist: {args.tar}'

    scene_splits = create_splits_scenes()

    eval_set_map = {
        'v1.0-mini': 'mini_trainval',
        'v1.0-trainval': 'val',
    }

    mini_scenes = scene_splits[eval_set_map[args.version]]

    # Find all target files
    print(f'ğŸ” Finding {args.name} files in {args.tar}...')
    target_files = find_files_with_name(args.tar, args.name)
    
    if not target_files:
        print(f"âŒ No {args.name} files found in {args.tar}")
        return

    # target_files ê° ìš”ì†Œì˜ ê²½ë¡œì—ì„œ ë¶€ëª¨ ë””ë ‰í† ë¦¬ ì¤‘ *_seq<number> íŒ¨í„´ì˜ ë§ˆì§€ë§‰ ìˆ«ì(ì”¬ ì¸ë±ìŠ¤)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    file_seq_pairs = []
    for target_file in target_files:
        seq_index = None
        for part in reversed(Path(target_file).parts):
            m = re.search(r"_seq(\d+)$", part)
            if m is not None:
                seq_index = int(m.group(1))
                break
        if seq_index is not None:
            file_seq_pairs.append((target_file, seq_index))
    tar_scene_indices = sorted({seq for _, seq in file_seq_pairs})
    if args.verbose:
        print(f"ğŸ¯ ì‚¬ìš©ë  scene ì¸ë±ìŠ¤ ì¶”ì¶œ: {tar_scene_indices}")

    # (íŒŒì¼ê²½ë¡œ, scene_name) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ìƒì„± ë° íŒŒìƒ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    target_file_scene_pairs = [
        (file_path, mini_scenes[idx])
        for file_path, idx in file_seq_pairs
        if 0 <= idx < len(mini_scenes)
    ]
    filtered_target_files = [file_path for file_path, _ in target_file_scene_pairs]
    target_scenes = [scene for _, scene in target_file_scene_pairs]
    if args.verbose:
        print(f"ğŸ¯ íŒŒì¼-ì”¬ ë§¤í•‘ ìˆ˜: {len(target_file_scene_pairs)}, scenes: {target_scenes}")

    # Initialize NuScenes
    nusc = NuScenes(
        version=args.version, dataroot=args.dataroot, verbose=False)
          

    
    config = config_factory('detection_cvpr_2019')
    
    # Load GT and Compare files
    print(f'ğŸ” Loading GT Boxes from: {args.gt}')
    gt_boxes, _ = load_gt(nusc, eval_set_map[args.version], DetectionBox, verbose=args.verbose)

    print(f'ğŸ” Loading Initial Boxes from: {args.ctrl}')
    ctrl_boxes, _ = load_prediction(args.ctrl, 
                                    config.max_boxes_per_sample, 
                                    DetectionBox,
                                    verbose=args.verbose)

    print(f'ğŸ” Loading Target Boxes from: {args.tar}')
    tar_boxes = extract_boxes_from_json_to_evalboxes_multiple(nusc, target_file_scene_pairs)
    print(f"âœ… target filesì—ì„œ {len(tar_boxes.sample_tokens)}ê°œ ìƒ˜í”Œ, {len(tar_boxes.all)}ê°œ ë°•ìŠ¤ ì¶”ì¶œ ì™„ë£Œ")
    
    # Filter to common scenes
    print("ğŸ” Filtering to common scenes...")
    gt_boxes, tar_boxes = filter_boxes_by_common_scenes(nusc, gt_boxes, tar_boxes)
    ctrl_boxes, tar_boxes = filter_boxes_by_common_scenes(nusc, ctrl_boxes, tar_boxes)

    # Prepare results storage
    results = []
           
    # Extract boxes from JSON file

    if len(tar_boxes.sample_tokens) == 0:
        print(f"âŒ No boxes extracted from {args.tar}")
        return
    
    # Perform correspondence matching
    if args.verbose:
        print("ğŸ”„ Performing correspondence matching...")            
            
    # Perform evaluation
    if args.verbose:
        print(f"\n    Performing target evaluation...")


    eval_results = perform_evaluation(gt_boxes, tar_boxes, tar_boxes.sample_tokens, config, nusc, args.tar)
    if args.verbose:
        print(f"\n    Performing control evaluation...")

    output_dir = Path(args.ctrl).parents[0]
    ctrl_boxes_matched = match_boxes(tar_boxes, ctrl_boxes)
    ctrl_eval_results = perform_evaluation(gt_boxes, ctrl_boxes_matched, ctrl_boxes_matched.sample_tokens, config, nusc, output_dir)

    # Extract iteration number from filename and parse metrics
    match = re.search(r'(\d+)', args.name)
    iteration_number = int(match.group(1)) if match else 80000

    result_entry = {
        'file_path': args.tar,
        'file_name': os.path.basename(args.tar),
        'directory': args.tar,
        **eval_results,
    }
    results.append(result_entry)
    
    if args.verbose:
        print(f"âœ… Evaluation completed for {args.tar}")
        print(f"   ATE: {eval_results['ATE']:.4f}, AOE: {eval_results['AOE']:.4f}, ASE: {eval_results['ASE']:.4f}")
    
    # Save results to CSV
    if results:
        df = pd.DataFrame(results)
        
        # Set output path
        if args.output is None:
            output_path = os.path.join(args.tar, f"instance_wise_eval_{args.name.replace('.', '_')}.csv")
        else:
            output_path = args.output
        
        df.to_csv(output_path, index=False)
        print(f"\nâœ… Results saved to: {output_path}")
        
    else:
        print("âŒ No results to save")


if __name__ == "__main__":
    main()
