import argparse
import numpy as np
import tqdm
from typing import Callable, Tuple, List, Dict
from collections import defaultdict, OrderedDict
from dataclasses import dataclass, asdict
import json
import os
from pathlib import Path
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
from pyquaternion import Quaternion
import open3d as o3d

from nuscenes import NuScenes
from nuscenes.eval.detection.evaluate import NuScenesEval
from nuscenes.eval.detection.config import config_factory
from nuscenes.eval.detection.data_classes import DetectionMetricData, DetectionBox, DetectionMetricDataList, DetectionMetrics
from nuscenes.eval.detection.utils import category_to_detection_name
from nuscenes.eval.detection.algo import calc_ap, calc_tp
from nuscenes.eval.detection.constants import TP_METRICS
from nuscenes.eval.tracking.data_classes import TrackingBox
from nuscenes.eval.common.data_classes import EvalBoxes
from nuscenes.eval.common.loaders import load_prediction, add_center_dist, filter_eval_boxes
from nuscenes.eval.common.utils import center_distance, scale_iou, yaw_diff, velocity_l2, attr_acc, cummean
from nuscenes.utils.splits import create_splits_scenes

@dataclass
class Annotation:
    token: str
    sample_token: str
    instance_token: str
    visibility_token: str
    attribute_tokens: List[str]
    translation: List[float]     # [x, y, z]
    size: List[float]            # [w, l, h]
    rotation: List[float]        # quaternion [w, x, y, z]
    prev: str
    next: str
    num_lidar_pts: int
    num_radar_pts: int

def load_gt(nusc: NuScenes, eval_split: str, box_cls, verbose: bool = False) -> Tuple[EvalBoxes, Dict[str, List]]:
    """
    Loads ground truth boxes from DB.
    :param nusc: A NuScenes instance.
    :param eval_split: The evaluation split for which we load GT boxes.
    :param box_cls: Type of box to load, e.g. DetectionBox or TrackingBox.
    :param verbose: Whether to print messages to stdout.
    :return: The GT boxes.
    """
    # Init.
    if box_cls == DetectionBox:
        attribute_map = {a['token']: a['name'] for a in nusc.attribute}

    if verbose:
        print('Loading annotations for {} split from nuScenes version: {}'.format(eval_split, nusc.version))
    # Read out all sample_tokens in DB.
    sample_tokens_all = [s['token'] for s in nusc.sample]
    assert len(sample_tokens_all) > 0, "Error: Database has no samples!"

    # Only keep samples from this split.
    splits = create_splits_scenes()

    # Check compatibility of split with nusc_version.
    version = nusc.version
    if eval_split in {'train', 'val', 'train_detect', 'train_track'}:
        assert version.endswith('trainval'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    elif eval_split in {'mini_train', 'mini_val'}:
        assert version.endswith('mini'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    elif eval_split == 'test':
        assert version.endswith('test'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    else:
        raise ValueError('Error: Requested split {} which this function cannot map to the correct NuScenes version.'
                         .format(eval_split))

    if eval_split == 'test':
        # Check that you aren't trying to cheat :).
        assert len(nusc.sample_annotation) > 0, \
            'Error: You are trying to evaluate on the test set but you do not have the annotations!'

    sample_tokens = []
    for sample_token in sample_tokens_all:
        scene_token = nusc.get('sample', sample_token)['scene_token']
        scene_record = nusc.get('scene', scene_token)
        if scene_record['name'] in splits[eval_split]:
            sample_tokens.append(sample_token)

    all_annotations = EvalBoxes()
    all_ann_tokens = defaultdict(list)
    # Load annotations and filter predictions and annotations.
    tracking_id_set = set()
    for sample_token in tqdm.tqdm(sample_tokens, leave=verbose):

        sample = nusc.get('sample', sample_token)
        sample_annotation_tokens = sample['anns']

        sample_boxes = []
        sample_ann_tokens = []
        for sample_annotation_token in sample_annotation_tokens:

            sample_annotation = nusc.get('sample_annotation', sample_annotation_token)
            if box_cls == DetectionBox:
                # Get label name in detection task and filter unused labels.
                detection_name = category_to_detection_name(sample_annotation['category_name'])
                if detection_name is None:
                    continue

                # Get attribute_name.
                attr_tokens = sample_annotation['attribute_tokens']
                attr_count = len(attr_tokens)
                if attr_count == 0:
                    attribute_name = ''
                elif attr_count == 1:
                    attribute_name = attribute_map[attr_tokens[0]]
                else:
                    raise Exception('Error: GT annotations must not have more than one attribute!')

                sample_boxes.append(
                    box_cls(
                        sample_token=sample_token,
                        translation=sample_annotation['translation'],
                        size=sample_annotation['size'],
                        rotation=sample_annotation['rotation'],
                        velocity=nusc.box_velocity(sample_annotation['token'])[:2],
                        num_pts=sample_annotation['num_lidar_pts'] + sample_annotation['num_radar_pts'],
                        detection_name=detection_name,
                        detection_score=-1.0,  # GT samples do not have a score.
                        attribute_name=attribute_name
                    )
                )
                sample_ann_tokens.append(sample_annotation_token)
            elif box_cls == TrackingBox:
                # Use nuScenes token as tracking id.
                tracking_id = sample_annotation['instance_token']
                tracking_id_set.add(tracking_id)

                # Get label name in detection task and filter unused labels.
                # Import locally to avoid errors when motmetrics package is not installed.
                from nuscenes.eval.tracking.utils import category_to_tracking_name
                tracking_name = category_to_tracking_name(sample_annotation['category_name'])
                if tracking_name is None:
                    continue

                sample_boxes.append(
                    box_cls(
                        sample_token=sample_token,
                        translation=sample_annotation['translation'],
                        size=sample_annotation['size'],
                        rotation=sample_annotation['rotation'],
                        velocity=nusc.box_velocity(sample_annotation['token'])[:2],
                        num_pts=sample_annotation['num_lidar_pts'] + sample_annotation['num_radar_pts'],
                        tracking_id=tracking_id,
                        tracking_name=tracking_name,
                        tracking_score=-1.0  # GT samples do not have a score.
                    )
                )
                sample_ann_tokens.append(sample_annotation_token)
            else:
                raise NotImplementedError('Error: Invalid box_cls %s!' % box_cls)

        all_annotations.add_boxes(sample_token, sample_boxes)
        all_ann_tokens[sample_token].extend(sample_ann_tokens)
    if verbose:
        print("Loaded ground truth annotations for {} samples.".format(len(all_annotations.sample_tokens)))

    return all_annotations, all_ann_tokens

def accumulate(gt_boxes: EvalBoxes,
                pred_boxes: EvalBoxes,
                sample_ann_tokens: Dict[str, List],
                class_name: str,
                dist_fcn: Callable,
                dist_th: float,
                verbose: bool = False) -> Tuple[DetectionMetricData, Dict[str, List[Tuple[str, DetectionBox]]]]:
    """
    Average Precision over predefined different recall thresholds for a single distance threshold.
    The recall/conf thresholds and other raw metrics will be used in secondary metrics.
    :param gt_boxes: Maps every sample_token to a list of its sample_annotations.
    :param pred_boxes: Maps every sample_token to a list of its sample_results.
    :param class_name: Class to compute AP on.
    :param dist_fcn: Distance function used to match detections and ground truths.
    :param dist_th: Distance threshold for a match.
    :param verbose: If true, print debug messages.
    :return: (average_prec, metrics). The average precision value and raw data for a number of metrics.
    """
    # ---------------------------------------------
    # Organize input and initialize accumulators.
    # ---------------------------------------------

    # Count the positives.
    npos = len([1 for gt_box in gt_boxes.all if gt_box.detection_name == class_name])
    if verbose:
        print("Found {} GT of class {} out of {} total across {} samples.".
              format(npos, class_name, len(gt_boxes.all), len(gt_boxes.sample_tokens)))

    # For missing classes in the GT, return a data structure corresponding to no predictions.
    if npos == 0:
        return DetectionMetricData.no_predictions()

    # Organize the predictions in a single list.
    pred_boxes_list = [box for box in pred_boxes.all if box.detection_name == class_name]
    pred_confs = [box.detection_score for box in pred_boxes_list]

    if verbose:
        print("Found {} PRED of class {} out of {} total across {} samples.".
              format(len(pred_confs), class_name, len(pred_boxes.all), len(pred_boxes.sample_tokens)))

    # Sort by confidence.
    sortind = [i for (v, i) in sorted((v, i) for (i, v) in enumerate(pred_confs))][::-1]

    # Do the actual matching.
    tp = []  # Accumulator of true positives.
    fp = []  # Accumulator of false positives.
    conf = []  # Accumulator of confidences.

    # match_data holds the extra metrics we calculate for each match.
    match_data = {'trans_err': [],
                  'vel_err': [],
                  'scale_err': [],
                  'orient_err': [],
                  'attr_err': [],
                  'conf': []}

    # ---------------------------------------------
    # Match and accumulate match data.
    # ---------------------------------------------

    taken = set()  # Initially no gt bounding box is matched.
    match_pred_boxes = defaultdict(list)

    for ind in sortind:
        pred_box = pred_boxes_list[ind]
        min_dist = np.inf
        match_gt_idx = None
        ann_tokens = sample_ann_tokens[pred_box.sample_token]

        for gt_idx, gt_box in enumerate(gt_boxes[pred_box.sample_token]):

            # Find closest match among ground truth boxes
            if gt_box.detection_name == class_name and not (pred_box.sample_token, gt_idx) in taken:
                this_distance = dist_fcn(gt_box, pred_box)
                if this_distance < min_dist:
                    min_dist = this_distance
                    match_gt_idx = gt_idx
                    match_ann_token = ann_tokens[gt_idx]

        # If the closest match is close enough according to threshold we have a match!
        is_match = min_dist < dist_th

        if is_match:
            taken.add((pred_box.sample_token, match_gt_idx))
            match_pred_boxes[pred_box.sample_token].append((match_ann_token, pred_box))

            #  Update tp, fp and confs.
            tp.append(1)
            fp.append(0)
            conf.append(pred_box.detection_score)

            # Since it is a match, update match data also.
            gt_box_match = gt_boxes[pred_box.sample_token][match_gt_idx]

            match_data['trans_err'].append(center_distance(gt_box_match, pred_box))
            match_data['vel_err'].append(velocity_l2(gt_box_match, pred_box))
            match_data['scale_err'].append(1 - scale_iou(gt_box_match, pred_box))

            # Barrier orientation is only determined up to 180 degree. (For cones orientation is discarded later)
            period = np.pi if class_name == 'barrier' else 2 * np.pi
            match_data['orient_err'].append(yaw_diff(gt_box_match, pred_box, period=period))

            match_data['attr_err'].append(1 - attr_acc(gt_box_match, pred_box))
            match_data['conf'].append(pred_box.detection_score)

        else:
            # No match. Mark this as a false positive.
            tp.append(0)
            fp.append(1)
            conf.append(pred_box.detection_score)

    # Check if we have any matches. If not, just return a "no predictions" array.
    if len(match_data['trans_err']) == 0:
        return DetectionMetricData.no_predictions()

    # ---------------------------------------------
    # Calculate and interpolate precision and recall
    # ---------------------------------------------

    # Accumulate.
    tp = np.cumsum(tp).astype(float)
    fp = np.cumsum(fp).astype(float)
    conf = np.array(conf)

    # Calculate precision and recall.
    prec = tp / (fp + tp)
    rec = tp / float(npos)

    rec_interp = np.linspace(0, 1, DetectionMetricData.nelem)  # 101 steps, from 0% to 100% recall.
    prec = np.interp(rec_interp, rec, prec, right=0)
    conf = np.interp(rec_interp, rec, conf, right=0)
    rec = rec_interp

    # ---------------------------------------------
    # Re-sample the match-data to match, prec, recall and conf.
    # ---------------------------------------------

    for key in match_data.keys():
        if key == "conf":
            continue  # Confidence is used as reference to align with fp and tp. So skip in this step.

        else:
            # For each match_data, we first calculate the accumulated mean.
            tmp = cummean(np.array(match_data[key]))

            # Then interpolate based on the confidences. (Note reversing since np.interp needs increasing arrays)
            match_data[key] = np.interp(conf[::-1], match_data['conf'][::-1], tmp[::-1])[::-1]

    # ---------------------------------------------
    # Done. Instantiate MetricData and return
    # ---------------------------------------------
    return DetectionMetricData(recall=rec,
                               precision=prec,
                               confidence=conf,
                               trans_err=match_data['trans_err'],
                               vel_err=match_data['vel_err'],
                               scale_err=match_data['scale_err'],
                               orient_err=match_data['orient_err'],
                               attr_err=match_data['attr_err']), match_pred_boxes
    
def read_nus_ann_file(dataroot: str, version: str) -> List[Annotation]:
    """NuScenes annotation íŒŒì¼ì„ ì½ì–´ì„œ Annotation ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        dataroot: NuScenes ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        version: NuScenes ë²„ì „ (e.g. 'v1.0-mini')
        
    Returns:
        List[Annotation]: Annotation ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    ann_path = os.path.join(dataroot, version, 'sample_annotation.json')
    with open(ann_path, 'r') as f:
        annotations = json.load(f)
    
    result = []
    for ann in annotations:
        result.append(Annotation(
            token=str(ann['token']),
            sample_token=str(ann['sample_token']),
            instance_token=str(ann['instance_token']),
            visibility_token=str(ann['visibility_token']),
            attribute_tokens=[str(token) for token in ann['attribute_tokens']],
            translation=[float(x) for x in ann['translation']],
            size=[float(x) for x in ann['size']],
            rotation=[float(x) for x in ann['rotation']],
            prev=str(ann['prev']),
            next=str(ann['next']),
            num_lidar_pts=int(ann['num_lidar_pts']),
            num_radar_pts=int(ann['num_radar_pts'])
        ))
    return result

def get_box_corners(translation, size, rotation):
    """3D ë°•ìŠ¤ì˜ 8ê°œ ê¼­ì§“ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        translation: [x, y, z] ì¤‘ì‹¬ì 
        size: [width, length, height] í¬ê¸°
        rotation: [w, x, y, z] ì¿¼í„°ë‹ˆì–¸
        
    Returns:
        8x3 numpy array: 8ê°œ ê¼­ì§“ì ì˜ ì¢Œí‘œ
    """
    w, l, h = size
    
    # ë¡œì»¬ ì¢Œí‘œê³„ì—ì„œì˜ 8ê°œ ê¼­ì§“ì  (ì¤‘ì‹¬ì´ ì›ì )
    corners_local = np.array([
        [-l/2, -w/2, -h/2],  # 0: ì¢Œí•˜í›„
        [l/2, -w/2, -h/2],   # 1: ìš°í•˜í›„
        [l/2, w/2, -h/2],    # 2: ìš°ìƒí›„
        [-l/2, w/2, -h/2],   # 3: ì¢Œìƒí›„
        [-l/2, -w/2, h/2],   # 4: ì¢Œí•˜ì „
        [l/2, -w/2, h/2],    # 5: ìš°í•˜ì „
        [l/2, w/2, h/2],     # 6: ìš°ìƒì „
        [-l/2, w/2, h/2]     # 7: ì¢Œìƒì „
    ])
    
    # pyquaternionì„ ì‚¬ìš©í•˜ì—¬ íšŒì „ ì ìš©
    q = Quaternion(rotation)  # [w, x, y, z] ìˆœì„œ
    rotation_matrix = q.rotation_matrix
    # ì˜¬ë°”ë¥¸ íšŒì „ ë³€í™˜: (rotation_matrix @ corners.T).T
    corners_rotated = (rotation_matrix @ corners_local.T).T
    
    # í‰í–‰ì´ë™ ì ìš©
    corners_world = corners_rotated + np.array(translation)
    
    return corners_world

def draw_3d_box(ax, corners, color='blue', alpha=0.3, edge_color='black'):
    """3D ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    
    Args:
        ax: matplotlib 3D axis
        corners: 8x3 numpy array, ë°•ìŠ¤ì˜ 8ê°œ ê¼­ì§“ì 
        color: ë°•ìŠ¤ ë©´ì˜ ìƒ‰ìƒ
        alpha: íˆ¬ëª…ë„
        edge_color: í…Œë‘ë¦¬ ìƒ‰ìƒ
    """
    # 12ê°œì˜ ë©´ì„ ì •ì˜ (ê° ë©´ì€ 4ê°œì˜ ê¼­ì§“ì ìœ¼ë¡œ êµ¬ì„±)
    faces = [
        [corners[0], corners[1], corners[2], corners[3]],  # ì•„ë˜ë©´
        [corners[4], corners[5], corners[6], corners[7]],  # ìœ„ë©´
        [corners[0], corners[1], corners[5], corners[4]],  # ì•ë©´
        [corners[2], corners[3], corners[7], corners[6]],  # ë’·ë©´
        [corners[1], corners[2], corners[6], corners[5]],  # ì˜¤ë¥¸ìª½ë©´
        [corners[4], corners[7], corners[3], corners[0]]   # ì™¼ìª½ë©´
    ]
    
    # Poly3DCollectionì„ ì‚¬ìš©í•´ì„œ ë©´ë“¤ì„ ê·¸ë¦¬ê¸°
    poly3d = [[tuple(face[j]) for j in range(len(face))] for face in faces]
    ax.add_collection3d(Poly3DCollection(poly3d, 
                                        facecolors=color, 
                                        linewidths=1, 
                                        edgecolors=edge_color,
                                        alpha=alpha))

# ===========================
# Open3D ì‹œê°í™” ìœ í‹¸ë¦¬í‹°
# ===========================

# Open3D LineSet ìƒì„±ì„ ìœ„í•œ ì—ì§€ ì¸ë±ìŠ¤ (12ê°œ)
OPEN3D_BOX_LINES = [
    [0, 1], [1, 2], [2, 3], [3, 0],  # ì•„ë˜ë©´
    [4, 5], [5, 6], [6, 7], [7, 4],  # ìœ„ë©´
    [0, 4], [1, 5], [2, 6], [3, 7]   # ì˜†ë©´
]

# -----------------------------
# NEW: Helper for front center sphere
# -----------------------------

def create_open3d_sphere(center: np.ndarray, radius: float, color: Tuple[float, float, float]) -> o3d.geometry.TriangleMesh:
    """ì§€ì •í•œ ì¤‘ì‹¬ê³¼ ìƒ‰ìƒì˜ êµ¬(Sphere) Meshë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        center (np.ndarray): ì¤‘ì‹¬ ì¢Œí‘œ (3,)
        radius (float): êµ¬ì˜ ë°˜ì§€ë¦„
        color (Tuple[float, float, float]): RGB ì»¬ëŸ¬ (0~1)

    Returns:
        o3d.geometry.TriangleMesh: ì‹œê°í™”ìš© Sphere Mesh
    """
    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius)
    sphere.translate(center)
    sphere.paint_uniform_color(color)
    return sphere

def create_open3d_box(corners: np.ndarray, color: Tuple[float, float, float]) -> o3d.geometry.LineSet:
    """8ê°œ ê¼­ì§“ì  ì •ë³´ë¡œë¶€í„° Open3D LineSet(ìœ¡ë©´ì²´) ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        corners (np.ndarray): (8, 3) í˜•íƒœì˜ ê¼­ì§“ì  ì¢Œí‘œ
        color (Tuple[float, float, float]): RGB ì»¬ëŸ¬ (0~1)

    Returns:
        o3d.geometry.LineSet: ì‹œê°í™”ìš© LineSet
    """
    line_set = o3d.geometry.LineSet()
    line_set.points = o3d.utility.Vector3dVector(corners)
    line_set.lines = o3d.utility.Vector2iVector(OPEN3D_BOX_LINES)
    line_set.colors = o3d.utility.Vector3dVector([color for _ in OPEN3D_BOX_LINES])
    return line_set


# noinspection PyBroadException
def visualize_ego_translations_open3d(pred_boxes: EvalBoxes, gt_boxes: EvalBoxes, scene_name: str = None,
                                      score_threshold: float = None, save_path: str = None, max_boxes: int = -1) -> None:
    """Open3Dë¥¼ ì´ìš©í•˜ì—¬ pred_boxesì™€ gt_boxesë¥¼ 3Dë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

    Args:
        pred_boxes: ì˜ˆì¸¡ ë°•ìŠ¤ë“¤
        gt_boxes: Ground truth ë°•ìŠ¤ë“¤
        scene_name: (ì„ íƒ) scene ì´ë¦„ (ì œëª© í‘œì‹œìš©)
        score_threshold: (ì„ íƒ) score threshold (ì œëª© í‘œì‹œìš©)
    """

    geometries = []

    # Coordinate frame ì¶”ê°€
    geometries.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=5.0))

    pred_count, gt_count = 0, 0
    center_translation = None

    # ì²« ë²ˆì§¸ ë°•ìŠ¤ì˜ translationì„ centerë¡œ ì„¤ì •
    for sample_token in pred_boxes.sample_tokens:
        for box in pred_boxes[sample_token]:
            if (hasattr(box, 'translation') and box.translation is not None and
                    hasattr(box, 'size') and box.size is not None and
                    hasattr(box, 'rotation') and box.rotation is not None):
                center_translation = np.array(box.translation)
                break
        if center_translation is not None:
            break

    if center_translation is None:
        print("ê¸°ì¤€ì´ ë  ë°•ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Prediction boxes (Red)
    for sample_token in pred_boxes.sample_tokens:
        for box in pred_boxes[sample_token]:
            if max_boxes > 0 and pred_count >= max_boxes:
                break  # ê°œìˆ˜ ì œí•œ ë„ë‹¬
            if (hasattr(box, 'translation') and box.translation is not None and
                    hasattr(box, 'size') and box.size is not None and
                    hasattr(box, 'rotation') and box.rotation is not None):
                
                # center ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚°
                relative_translation = np.array(box.translation) - center_translation
                corners = get_box_corners(relative_translation, box.size, box.rotation)
                geometries.append(create_open3d_box(corners, (1.0, 0.0, 0.0)))  # Red

                # NEW: ì•ë©´ ì¤‘ì‹¬ì  ì‹œê°í™” (Red)
                # front_center = np.mean(corners[4:8], axis=0)
                front_center = (corners[1] + corners[6]) / 2 
                geometries.append(create_open3d_sphere(front_center, radius=0.1, color=(1.0, 0.0, 0.0)))

                pred_count += 1
        if max_boxes > 0 and pred_count >= max_boxes:
            break

    # Ground truth boxes (Blue)
    for sample_token in gt_boxes.sample_tokens:
        for box in gt_boxes[sample_token]:
            if max_boxes > 0 and gt_count >= max_boxes:
                break  # ê°œìˆ˜ ì œí•œ ë„ë‹¬
            if (hasattr(box, 'translation') and box.translation is not None and
                    hasattr(box, 'size') and box.size is not None and
                    hasattr(box, 'rotation') and box.rotation is not None):

                # center ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚°
                relative_translation = np.array(box.translation) - center_translation
                corners = get_box_corners(relative_translation, box.size, box.rotation)
                geometries.append(create_open3d_box(corners, (0.0, 0.0, 1.0)))  # Blue

                # NEW: ì•ë©´ ì¤‘ì‹¬ì  ì‹œê°í™” (Blue)
                # front_center = np.mean(corners[4:8], axis=0)
                front_center = (corners[1] + corners[6]) / 2 
                geometries.append(create_open3d_sphere(front_center, radius=0.1, color=(0.0, 0.0, 1.0)))

                gt_count += 1
        if max_boxes > 0 and gt_count >= max_boxes:
            break

    if pred_count == 0 and gt_count == 0:
        print("ì‹œê°í™”í•  ë°•ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìœˆë„ìš° ì´ë¦„ ì„¤ì •
    window_name = "Open3D Visualization of Detection Boxes"
    subtitle_parts = []
    if scene_name:
        subtitle_parts.append(f"Scene: {scene_name}")
    if score_threshold is not None and score_threshold > 0:
        subtitle_parts.append(f"Scoreâ‰¥{score_threshold}")
    subtitle_parts.append(f"Pred: {pred_count}, GT: {gt_count}")
    if subtitle_parts:
        window_name += " (" + " | ".join(subtitle_parts) + ")"

    # ---------------------------
    # ì‹œê°í™” (ì˜¨ìŠ¤í¬ë¦° or ì˜¤í”„ìŠ¤í¬ë¦°)
    # ---------------------------

    # 1) ì˜¤í”„ìŠ¤í¬ë¦° ë Œë”ë§ ëª¨ë“œê°€ í•„ìš”í•œ ê²½ìš° (save_path ì§€ì • or GUI ì‚¬ìš© ë¶ˆê°€)
    if save_path is not None:
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False)
        for g in geometries:
            vis.add_geometry(g)
        vis.poll_events()
        vis.update_renderer()
        vis.capture_screen_image(save_path)
        vis.destroy_window()
        print(f"âœ… 3D ì‹œê°í™” ê²°ê³¼ê°€ '{save_path}' ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # 2) ì¼ë°˜ ìœˆë„ìš° ëª¨ë“œ (GUI ê°€ëŠ¥ í™˜ê²½)
    try:
        o3d.visualization.draw_geometries(geometries, window_name=window_name)
    except Exception as e:
        print("âš ï¸ Open3D GUI ì°½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Headless í™˜ê²½ìœ¼ë¡œ íŒë‹¨)\n   â†’ ì˜¤ë¥˜ ë©”ì‹œì§€:", e)
        print("ëŒ€ì‹  ì˜¤í”„ìŠ¤í¬ë¦° ëª¨ë“œë¡œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. '--save_plot <ê²½ë¡œ>' ì¸ìë¥¼ ì§€ì •í•˜ì„¸ìš”.")

# -----------------------------------------------------------------------------
# ë°•ìŠ¤ í•„í„°ë§ ìœ í‹¸ë¦¬í‹° (Score / Scene)
# -----------------------------------------------------------------------------

def filter_boxes_by_score(boxes: EvalBoxes, score_threshold: float) -> EvalBoxes:
    """detection_scoreê°€ threshold ì´ìƒì¸ boxesë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        boxes: í•„í„°ë§í•  EvalBoxes
        score_threshold: score threshold (ì´ ê°’ ì´ìƒì¸ ë°•ìŠ¤ë“¤ë§Œ ìœ ì§€)

    Returns:
        í•„í„°ë§ëœ EvalBoxes
    """
    filtered_boxes = EvalBoxes()
    total_boxes = 0
    filtered_count = 0

    for sample_token in boxes.sample_tokens:
        sample_boxes = []
        for box in boxes[sample_token]:
            total_boxes += 1
            if hasattr(box, 'detection_score') and box.detection_score >= score_threshold:
                sample_boxes.append(box)
                filtered_count += 1

        if sample_boxes:  # í•„í„°ë§ëœ ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
            filtered_boxes.add_boxes(sample_token, sample_boxes)

    print(f"âœ… Score {score_threshold} ì´ìƒì¸ ë°•ìŠ¤: {filtered_count}/{total_boxes}ê°œ")
    return filtered_boxes


def filter_boxes_by_scene(nusc: NuScenes, boxes: EvalBoxes, scene_name: str) -> EvalBoxes:
    """íŠ¹ì • sceneì— í•´ë‹¹í•˜ëŠ” boxesë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        nusc: NuScenes ê°ì²´
        boxes: í•„í„°ë§í•  EvalBoxes
        scene_name: í•„í„°ë§í•  scene ì´ë¦„ (ì˜ˆ: 'scene-0061')

    Returns:
        í•„í„°ë§ëœ EvalBoxes
    """
    # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
    scene_token = None
    for scene in nusc.scene:
        if scene['name'] == scene_name:
            scene_token = scene['token']
            break

    if scene_token is None:
        print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return EvalBoxes()

    # í•´ë‹¹ sceneì˜ sample_tokens ê°€ì ¸ì˜¤ê¸°
    scene_sample_tokens = []
    for sample_token in boxes.sample_tokens:
        sample = nusc.get('sample', sample_token)
        if sample['scene_token'] == scene_token:
            scene_sample_tokens.append(sample_token)

    # í•„í„°ë§ëœ ë°•ìŠ¤ë“¤ë¡œ ìƒˆë¡œìš´ EvalBoxes ìƒì„±
    filtered_boxes = EvalBoxes()
    for sample_token in scene_sample_tokens:
        if sample_token in boxes.sample_tokens:
            filtered_boxes.add_boxes(sample_token, boxes[sample_token])

    print(f"âœ… Scene '{scene_name}'ì—ì„œ {len(scene_sample_tokens)}ê°œì˜ ìƒ˜í”Œì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return filtered_boxes


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Convert NuScenes detection JSON to pandas DataFrame")
    parser.add_argument(
        "--pred",
        type=str,
        default="/workspace/drivestudio/output/feasibility_check/run_original_scene_0_date_0529_try_1/keyframe_instance_poses_data/all_poses.json",
        # default="/workspace/drivestudio/output/feasibility_check/run_original_scene_0_date_0529_try_1/test/results_nusc.json",
        help="Path to prediction json",
    )
    parser.add_argument(
        "--version",
        type=str,
        default="v1.0-mini",
        help="NuScenes version",
    )
    parser.add_argument(
        "--dataroot",
        type=str,
        default="/workspace/drivestudio/data/nuscenes/raw",
        help="NuScenes dataroot",
    )
    parser.add_argument(
        "--verbose",
        type=bool,
        default=True,
        help="Verbose",
    )
    parser.add_argument(
        "--save_plot",
        type=str,
        default=None,
        help="Path to save the 3D visualization plot"
    )
    parser.add_argument(
        "--scene_name",
        type=str,
        default='scene-0061',
        help="Scene name to filter boxes"
    )
    parser.add_argument(
        "--score_threshold",
        type=float,
        default=0.5,
        help="Minimum detection score threshold for pred_boxes"
    )
    parser.add_argument(
        "--max_boxes",
        type=int,
        default=500,
        help="ì‹œê°í™”í•  ìµœëŒ€ ë°•ìŠ¤ ê°œìˆ˜ (<=0 ì´ë©´ ì œí•œ ì—†ìŒ)"
    )

    args = parser.parse_args()

    nusc = NuScenes(
        version=args.version, dataroot=args.dataroot, verbose=args.verbose)
    eval_set_map = {
        'v1.0-mini': 'mini_val',
        'v1.0-trainval': 'val',
    }

    assert os.path.exists(args.pred), 'Error: The result file does not exist!'
    config = config_factory('detection_cvpr_2019')

    pred_boxes, meta = load_prediction(args.pred, 
                                        config.max_boxes_per_sample, 
                                        DetectionBox,
                                        verbose=args.verbose)

    gt_boxes, sample_ann_tokens = load_gt(nusc, eval_set_map[args.version], DetectionBox, verbose=args.verbose)
    
    # Filter pred_boxes by score
    if args.score_threshold > 0:
        print(f"ğŸ“Š Score threshold {args.score_threshold}ë¡œ pred_boxes í•„í„°ë§ ì¤‘...")
        pred_boxes = filter_boxes_by_score(pred_boxes, args.score_threshold)
    
    # Filter boxes by scene
    if args.scene_name:
        pred_boxes = filter_boxes_by_scene(nusc, pred_boxes, args.scene_name)
        gt_boxes = filter_boxes_by_scene(nusc, gt_boxes, args.scene_name)
    
    assert set(pred_boxes.sample_tokens) == set(gt_boxes.sample_tokens), \
        "Samples in split doesn't match samples in predictions."

    
    # Open3D 3D ì‹œê°í™”
    print("Open3D 3D ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
    visualize_ego_translations_open3d(pred_boxes, gt_boxes, args.scene_name, args.score_threshold, args.save_plot, args.max_boxes)

if __name__ == "__main__":
    main()
    
