import argparse
import numpy as np
import tqdm
from typing import Callable, Tuple, List, Dict, Optional
from collections import defaultdict, OrderedDict
from dataclasses import dataclass, asdict
import json
import os
from pathlib import Path
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
from pyquaternion import Quaternion
import open3d as o3d
import open3d.visualization
import ctypes

from nuscenes import NuScenes
from nuscenes.eval.detection.evaluate import NuScenesEval
from nuscenes.eval.detection.config import config_factory
from nuscenes.eval.detection.data_classes import DetectionMetricData, DetectionBox, DetectionMetricDataList, DetectionMetrics
from nuscenes.eval.detection.utils import category_to_detection_name
from nuscenes.eval.detection.algo import calc_ap, calc_tp
from nuscenes.eval.detection.constants import TP_METRICS
from nuscenes.eval.tracking.data_classes import TrackingBox
from nuscenes.eval.common.data_classes import EvalBoxes
from nuscenes.eval.common.loaders import load_prediction, add_center_dist, filter_eval_boxes
from nuscenes.eval.common.utils import center_distance, scale_iou, yaw_diff, velocity_l2, attr_acc, cummean
from nuscenes.utils.splits import create_splits_scenes
from nuscenes.utils.data_classes import LidarPointCloud
import abc
from typing import Union

class EvalBox(abc.ABC):
    """ Abstract base class for data classes used during detection evaluation. Can be a prediction or ground truth."""

    def __init__(self,
                 sample_token: str = "",
                 translation: Tuple[float, float, float] = (0, 0, 0),
                 size: Tuple[float, float, float] = (0, 0, 0),
                 rotation: Tuple[float, float, float, float] = (0, 0, 0, 0),
                 velocity: Tuple[float, float] = (0, 0),
                 ego_translation: Tuple[float, float, float] = (0, 0, 0),  # Translation to ego vehicle in meters.
                 ego_rotation: Tuple[float, float, float, float] = (0, 0, 0, 0),
                 num_pts: int = -1):  # Nbr. LIDAR or RADAR inside the box. Only for gt boxes.

        # Assert data for shape and NaNs.
        assert type(sample_token) == str, 'Error: sample_token must be a string!'

        assert len(translation) == 3, 'Error: Translation must have 3 elements!'
        assert not np.any(np.isnan(translation)), 'Error: Translation may not be NaN!'

        assert len(size) == 3, 'Error: Size must have 3 elements!'
        assert not np.any(np.isnan(size)), 'Error: Size may not be NaN!'

        assert len(rotation) == 4, 'Error: Rotation must have 4 elements!'
        assert not np.any(np.isnan(rotation)), 'Error: Rotation may not be NaN!'

        # Velocity can be NaN from our database for certain annotations.
        assert len(velocity) == 2, 'Error: Velocity must have 2 elements!'

        assert len(ego_translation) == 3, 'Error: Translation must have 3 elements!'
        assert not np.any(np.isnan(ego_translation)), 'Error: Translation may not be NaN!'

        assert type(num_pts) == int, 'Error: num_pts must be int!'
        assert not np.any(np.isnan(num_pts)), 'Error: num_pts may not be NaN!'

        # Assign.
        self.sample_token = sample_token
        self.translation = translation
        self.size = size
        self.rotation = rotation
        self.velocity = velocity
        self.ego_translation = ego_translation
        self.ego_rotation = ego_rotation
        self.num_pts = num_pts

    @property
    def ego_dist(self) -> float:
        """ Compute the distance from this box to the ego vehicle in 2D. """
        return np.sqrt(np.sum(np.array(self.ego_translation[:2]) ** 2))

    def __repr__(self):
        return str(self.serialize())

    @abc.abstractmethod
    def serialize(self) -> dict:
        pass

    @classmethod
    @abc.abstractmethod
    def deserialize(cls, content: dict):
        pass


def load_gt(nusc: NuScenes, eval_split: str, box_cls, verbose: bool = False) -> Tuple[EvalBoxes, Dict[str, List]]:
    """
    Loads ground truth boxes from DB.
    :param nusc: A NuScenes instance.
    :param eval_split: The evaluation split for which we load GT boxes.
    :param box_cls: Type of box to load, e.g. DetectionBox or TrackingBox.
    :param verbose: Whether to print messages to stdout.
    :return: The GT boxes.
    """
    # Init.
    if box_cls == DetectionBox:
        attribute_map = {a['token']: a['name'] for a in nusc.attribute}

    if verbose:
        print('Loading annotations for {} split from nuScenes version: {}'.format(eval_split, nusc.version))
    # Read out all sample_tokens in DB.
    sample_tokens_all = [s['token'] for s in nusc.sample]
    assert len(sample_tokens_all) > 0, "Error: Database has no samples!"

    # Only keep samples from this split.
    splits = create_splits_scenes()

    # Check compatibility of split with nusc_version.
    version = nusc.version
    if eval_split in {'train', 'val', 'train_detect', 'train_track'}:
        assert version.endswith('trainval'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    elif eval_split in {'mini_train', 'mini_val'}:
        assert version.endswith('mini'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    elif eval_split == 'test':
        assert version.endswith('test'), \
            'Error: Requested split {} which is not compatible with NuScenes version {}'.format(eval_split, version)
    else:
        raise ValueError('Error: Requested split {} which this function cannot map to the correct NuScenes version.'
                         .format(eval_split))

    if eval_split == 'test':
        # Check that you aren't trying to cheat :).
        assert len(nusc.sample_annotation) > 0, \
            'Error: You are trying to evaluate on the test set but you do not have the annotations!'

    sample_tokens = []
    for sample_token in sample_tokens_all:
        scene_token = nusc.get('sample', sample_token)['scene_token']
        scene_record = nusc.get('scene', scene_token)
        if scene_record['name'] in splits[eval_split]:
            sample_tokens.append(sample_token)

    all_annotations = EvalBoxes()
    all_ann_tokens = defaultdict(list)
    # Load annotations and filter predictions and annotations.
    tracking_id_set = set()
    for sample_token in tqdm.tqdm(sample_tokens, leave=verbose):

        sample = nusc.get('sample', sample_token)
        sample_annotation_tokens = sample['anns']

        sample_boxes = []
        sample_ann_tokens = []
        for sample_annotation_token in sample_annotation_tokens:

            sample_annotation = nusc.get('sample_annotation', sample_annotation_token)
            if box_cls == DetectionBox:
                # Get label name in detection task and filter unused labels.
                detection_name = category_to_detection_name(sample_annotation['category_name'])
                if detection_name is None:
                    continue

                # Get attribute_name.
                attr_tokens = sample_annotation['attribute_tokens']
                attr_count = len(attr_tokens)
                if attr_count == 0:
                    attribute_name = ''
                elif attr_count == 1:
                    attribute_name = attribute_map[attr_tokens[0]]
                else:
                    raise Exception('Error: GT annotations must not have more than one attribute!')

                sample_boxes.append(
                    box_cls(
                        sample_token=sample_token,
                        translation=sample_annotation['translation'],
                        size=sample_annotation['size'],
                        rotation=sample_annotation['rotation'],
                        velocity=nusc.box_velocity(sample_annotation['token'])[:2],
                        num_pts=sample_annotation['num_lidar_pts'] + sample_annotation['num_radar_pts'],
                        detection_name=detection_name,
                        detection_score=-1.0,  # GT samples do not have a score.
                        attribute_name=attribute_name
                    )
                )
                sample_ann_tokens.append(sample_annotation_token)
            elif box_cls == TrackingBox:
                # Use nuScenes token as tracking id.
                tracking_id = sample_annotation['instance_token']
                tracking_id_set.add(tracking_id)

                # Get label name in detection task and filter unused labels.
                # Import locally to avoid errors when motmetrics package is not installed.
                from nuscenes.eval.tracking.utils import category_to_tracking_name
                tracking_name = category_to_tracking_name(sample_annotation['category_name'])
                if tracking_name is None:
                    continue

                sample_boxes.append(
                    box_cls(
                        sample_token=sample_token,
                        translation=sample_annotation['translation'],
                        size=sample_annotation['size'],
                        rotation=sample_annotation['rotation'],
                        velocity=nusc.box_velocity(sample_annotation['token'])[:2],
                        num_pts=sample_annotation['num_lidar_pts'] + sample_annotation['num_radar_pts'],
                        tracking_id=tracking_id,
                        tracking_name=tracking_name,
                        tracking_score=-1.0  # GT samples do not have a score.
                    )
                )
                sample_ann_tokens.append(sample_annotation_token)
            else:
                raise NotImplementedError('Error: Invalid box_cls %s!' % box_cls)

        all_annotations.add_boxes(sample_token, sample_boxes)
        all_ann_tokens[sample_token].extend(sample_ann_tokens)
    if verbose:
        print("Loaded ground truth annotations for {} samples.".format(len(all_annotations.sample_tokens)))

    return all_annotations, all_ann_tokens

def add_ego_pose(nusc: NuScenes,
                    eval_boxes: EvalBoxes):
    """
    Adds the ego pose information (translation and rotation) to each box.
    :param nusc: The NuScenes instance.
    :param eval_boxes: A set of boxes, either GT or predictions.
    :return: eval_boxes augmented with ego pose information.
    """
    for sample_token in eval_boxes.sample_tokens:
        sample_rec = nusc.get('sample', sample_token)
        sd_record = nusc.get('sample_data', sample_rec['data']['LIDAR_TOP'])
        pose_record = nusc.get('ego_pose', sd_record['ego_pose_token'])

        # Get ego pose transformation
        ego_translation_global = np.array(pose_record['translation'])
        ego_rotation_global = Quaternion(pose_record['rotation'])

        for box in eval_boxes[sample_token]:
            # Convert global coordinates to ego vehicle local coordinates
            
            # Step 1: Get relative position vector in global coordinates
            box_translation_global = np.array(box.translation)
            relative_translation_global = box_translation_global - ego_translation_global
            
            # Step 2: Rotate this position vector to ego vehicle's local coordinate system
            # This transforms "relative position in global frame" to "relative position in ego frame"
            # Example: if ego is rotated 90Â°, what's "north" in global becomes "left" in ego frame
            ego_translation_array = ego_rotation_global.inverse.rotate(relative_translation_global)
            
            # Step 3: Transform box rotation to ego coordinates
            box_rotation_global = Quaternion(list(box.rotation))  # type: ignore
            ego_rotation = ego_rotation_global.inverse * box_rotation_global
            
            if isinstance(box, DetectionBox) or isinstance(box, TrackingBox):
                box.ego_translation = tuple(ego_translation_array)
                # Add ego_rotation attribute dynamically
                setattr(box, 'ego_rotation', tuple([ego_rotation.w, ego_rotation.x, ego_rotation.y, ego_rotation.z]))  # type: ignore
            else:
                raise NotImplementedError

    return eval_boxes

def get_box_corners(translation, size, rotation):
    """3D ë°•ìŠ¤ì˜ 8ê°œ ê¼­ì§“ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        translation: [x, y, z] ì¤‘ì‹¬ì 
        size: [width, length, height] í¬ê¸°
        rotation: [w, x, y, z] ì¿¼í„°ë‹ˆì–¸
        
    Returns:
        8x3 numpy array: 8ê°œ ê¼­ì§“ì ì˜ ì¢Œí‘œ
    """
    w, l, h = size
    
    # ë¡œì»¬ ì¢Œí‘œê³„ì—ì„œì˜ 8ê°œ ê¼­ì§“ì  (ì¤‘ì‹¬ì´ ì›ì )
    corners_local = np.array([
        [-l/2, -w/2, -h/2],  # 0: ì¢Œí•˜í›„
        [l/2, -w/2, -h/2],   # 1: ìš°í•˜í›„
        [l/2, w/2, -h/2],    # 2: ìš°ìƒí›„
        [-l/2, w/2, -h/2],   # 3: ì¢Œìƒí›„
        [-l/2, -w/2, h/2],   # 4: ì¢Œí•˜ì „
        [l/2, -w/2, h/2],    # 5: ìš°í•˜ì „
        [l/2, w/2, h/2],     # 6: ìš°ìƒì „
        [-l/2, w/2, h/2]     # 7: ì¢Œìƒì „
    ])
    
    # pyquaternionì„ ì‚¬ìš©í•˜ì—¬ íšŒì „ ì ìš©
    q = Quaternion(rotation)  # [w, x, y, z] ìˆœì„œ
    rotation_matrix = q.rotation_matrix
    # ì˜¬ë°”ë¥¸ íšŒì „ ë³€í™˜: (rotation_matrix @ corners.T).T
    corners_rotated = (rotation_matrix @ corners_local.T).T
    
    # í‰í–‰ì´ë™ ì ìš©
    corners_world = corners_rotated + np.array(translation)
    
    return corners_world

def draw_3d_box(ax, corners, color='blue', alpha=0.3, edge_color='black'):
    """3D ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
    
    Args:
        ax: matplotlib 3D axis
        corners: 8x3 numpy array, ë°•ìŠ¤ì˜ 8ê°œ ê¼­ì§“ì 
        color: ë°•ìŠ¤ ë©´ì˜ ìƒ‰ìƒ
        alpha: íˆ¬ëª…ë„
        edge_color: í…Œë‘ë¦¬ ìƒ‰ìƒ
    """
    # 12ê°œì˜ ë©´ì„ ì •ì˜ (ê° ë©´ì€ 4ê°œì˜ ê¼­ì§“ì ìœ¼ë¡œ êµ¬ì„±)
    faces = [
        [corners[0], corners[1], corners[2], corners[3]],  # ì•„ë˜ë©´
        [corners[4], corners[5], corners[6], corners[7]],  # ìœ„ë©´
        [corners[0], corners[1], corners[5], corners[4]],  # ì•ë©´
        [corners[2], corners[3], corners[7], corners[6]],  # ë’·ë©´
        [corners[1], corners[2], corners[6], corners[5]],  # ì˜¤ë¥¸ìª½ë©´
        [corners[4], corners[7], corners[3], corners[0]]   # ì™¼ìª½ë©´
    ]
    
    # Poly3DCollectionì„ ì‚¬ìš©í•´ì„œ ë©´ë“¤ì„ ê·¸ë¦¬ê¸°
    poly3d = [[tuple(face[j]) for j in range(len(face))] for face in faces]
    ax.add_collection3d(Poly3DCollection(poly3d, 
                                        facecolors=color, 
                                        linewidths=1, 
                                        edgecolors=edge_color,
                                        alpha=alpha))

# ===========================
# Open3D ì‹œê°í™” ìœ í‹¸ë¦¬í‹°
# ===========================

# Open3D LineSet ìƒì„±ì„ ìœ„í•œ ì—ì§€ ì¸ë±ìŠ¤ (12ê°œ)
OPEN3D_BOX_LINES = [
    [0, 1], [1, 2], [2, 3], [3, 0],  # ì•„ë˜ë©´
    [4, 5], [5, 6], [6, 7], [7, 4],  # ìœ„ë©´
    [0, 4], [1, 5], [2, 6], [3, 7]   # ì˜†ë©´
]

# -----------------------------
# NEW: Helper for front center sphere
# -----------------------------

def create_open3d_sphere(center: np.ndarray, radius: float, color: Tuple[float, float, float]) -> o3d.geometry.TriangleMesh:
    """ì§€ì •í•œ ì¤‘ì‹¬ê³¼ ìƒ‰ìƒì˜ êµ¬(Sphere) Meshë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        center (np.ndarray): ì¤‘ì‹¬ ì¢Œí‘œ (3,)
        radius (float): êµ¬ì˜ ë°˜ì§€ë¦„
        color (Tuple[float, float, float]): RGB ì»¬ëŸ¬ (0~1)

    Returns:
        o3d.geometry.TriangleMesh: ì‹œê°í™”ìš© Sphere Mesh
    """
    sphere = o3d.geometry.TriangleMesh.create_sphere(radius=radius)
    sphere.translate(center)
    sphere.paint_uniform_color(color)
    return sphere

def create_open3d_box(corners: np.ndarray, color: Tuple[float, float, float]) -> o3d.geometry.TriangleMesh:
    """8ê°œ ê¼­ì§“ì  ì •ë³´ë¡œë¶€í„° Open3D ë‘êº¼ìš´ ì„ ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ìœ¡ë©´ì²´ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        corners (np.ndarray): (8, 3) í˜•íƒœì˜ ê¼­ì§“ì  ì¢Œí‘œ
        color (Tuple[float, float, float]): RGB ì»¬ëŸ¬ (0~1)

    Returns:
        o3d.geometry.TriangleMesh: ì‹œê°í™”ìš© ë‘êº¼ìš´ ì„  ë°•ìŠ¤
    """
    # ì„  ë‘ê»˜ ì„¤ì •
    line_radius = 0.05  # ì„ ì˜ ë°˜ì§€ë¦„ (ë‘ê»˜ ì¡°ì ˆ)
    
    # ëª¨ë“  ì‹¤ë¦°ë”ë¥¼ í•©ì¹  ë©”ì‰¬
    combined_mesh = o3d.geometry.TriangleMesh()
    
    # 12ê°œì˜ ëª¨ì„œë¦¬ì— ëŒ€í•´ ì‹¤ë¦°ë” ìƒì„±
    for line_indices in OPEN3D_BOX_LINES:
        start_point = corners[line_indices[0]]
        end_point = corners[line_indices[1]]
        
        # ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚°
        line_vector = end_point - start_point
        line_length = np.linalg.norm(line_vector)
        
        if line_length < 1e-6:  # ë„ˆë¬´ ì§§ì€ ì„ ì€ ê±´ë„ˆë›°ê¸°
            continue
            
        # ì‹¤ë¦°ë” ìƒì„± (Zì¶• ë°©í–¥ìœ¼ë¡œ ìƒì„±ë¨)
        cylinder = o3d.geometry.TriangleMesh.create_cylinder(
            radius=line_radius, 
            height=line_length,
            resolution=8  # ì‹¤ë¦°ë”ì˜ í•´ìƒë„ (ë‚®ìœ¼ë©´ ì„±ëŠ¥ í–¥ìƒ)
        )
        
        # ì‹¤ë¦°ë”ë¥¼ ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œ íšŒì „ì‹œí‚¤ê¸°
        # Zì¶• ë‹¨ìœ„ë²¡í„°
        z_axis = np.array([0, 0, 1])
        # ì„ ì˜ ë°©í–¥ ë²¡í„°
        line_direction = line_vector / line_length
        
        # íšŒì „ì¶• ê³„ì‚° (ì™¸ì )
        rotation_axis = np.cross(z_axis, line_direction)
        rotation_axis_norm = np.linalg.norm(rotation_axis)
        
        if rotation_axis_norm > 1e-6:  # í‰í–‰í•˜ì§€ ì•Šì€ ê²½ìš°
            # íšŒì „ê° ê³„ì‚°
            cos_angle = np.dot(z_axis, line_direction)
            angle = np.arccos(np.clip(cos_angle, -1.0, 1.0))
            
            # íšŒì „ì¶• ì •ê·œí™”
            rotation_axis = rotation_axis / rotation_axis_norm
            
            # íšŒì „ í–‰ë ¬ ìƒì„±
            rotation_matrix = o3d.geometry.get_rotation_matrix_from_axis_angle(
                rotation_axis * angle
            )
            
            # ì‹¤ë¦°ë” íšŒì „
            cylinder.rotate(rotation_matrix, center=(0, 0, 0))
        
        # ì‹¤ë¦°ë”ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ì´ë™ (ì‹¤ë¦°ë” ì¤‘ì‹¬ì´ ì„ ì˜ ì¤‘ì ì´ ë˜ë„ë¡)
        cylinder_center = (start_point + end_point) / 2
        cylinder.translate(cylinder_center)
        
        # ìƒ‰ìƒ ì ìš©
        cylinder.paint_uniform_color(color)
        
        # ë©”ì‰¬ í•©ì¹˜ê¸°
        combined_mesh += cylinder
    
    return combined_mesh


def load_lidar_pointcloud(nusc: NuScenes, sample_token: str) -> Optional[np.ndarray]:
    """NuScenes sampleì—ì„œ LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ë¡œë“œí•˜ê³  ego vehicle ì¢Œí‘œê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        nusc: NuScenes ê°ì²´
        sample_token: sample token
        
    Returns:
        ego vehicle ì¢Œí‘œê³„ì˜ í¬ì¸íŠ¸ í´ë¼ìš°ë“œ numpy array (N, 3) ë˜ëŠ” None
    """
    try:
        # sample ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        sample = nusc.get('sample', sample_token)
        
        # LiDAR ë°ì´í„° í† í° ê°€ì ¸ì˜¤ê¸°
        lidar_token = sample['data']['LIDAR_TOP']
        
        # sample_data ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        sample_data = nusc.get('sample_data', lidar_token)
        
        # LiDAR íŒŒì¼ ê²½ë¡œ
        lidar_path = os.path.join(nusc.dataroot, sample_data['filename'])
        
        if not os.path.exists(lidar_path):
            print(f"âš ï¸ LiDAR íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {lidar_path}")
            return None
            
        # LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë“œ (ì„¼ì„œ ì¢Œí‘œê³„)
        pc = LidarPointCloud.from_file(lidar_path)
        
        # LiDAR extrinsic calibration ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        calibrated_sensor = nusc.get('calibrated_sensor', sample_data['calibrated_sensor_token'])
        
        # LiDAR extrinsic: ì„¼ì„œ -> ego vehicle ë³€í™˜
        lidar_translation = np.array(calibrated_sensor['translation'])
        lidar_rotation = Quaternion(calibrated_sensor['rotation'])
        
        # í¬ì¸íŠ¸ë¥¼ ego vehicle ì¢Œí‘œê³„ë¡œ ë³€í™˜
        # Step 1: LiDAR ì„¼ì„œ ì¢Œí‘œê³„ì˜ í¬ì¸íŠ¸ë“¤ (x, y, z)
        points_sensor = pc.points[:3, :]  # (3, N)
        
        # Step 2: LiDAR rotation ì ìš©
        points_rotated = lidar_rotation.rotation_matrix @ points_sensor  # (3, N)
        
        # Step 3: LiDAR translation ì ìš©
        points_ego = points_rotated + lidar_translation.reshape(3, 1)  # (3, N)
        
        # (N, 3) í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        return points_ego.T
        
    except Exception as e:
        print(f"âš ï¸ LiDAR ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def create_open3d_pointcloud(points: np.ndarray, color: Optional[Tuple[float, float, float]] = None,
                            max_points: int = 50000) -> o3d.geometry.PointCloud:
    """numpy arrayë¡œë¶€í„° Open3D PointCloud ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        points: (N, 3) í˜•íƒœì˜ í¬ì¸íŠ¸ ì¢Œí‘œ
        color: RGB ìƒ‰ìƒ (0~1), Noneì´ë©´ ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ ì‚¬ìš©
        max_points: ìµœëŒ€ í¬ì¸íŠ¸ ê°œìˆ˜ (ì„±ëŠ¥ì„ ìœ„í•´ ì œí•œ)
        
    Returns:
        Open3D PointCloud ê°ì²´
    """
    # í¬ì¸íŠ¸ ê°œìˆ˜ ì œí•œ
    if len(points) > max_points:
        # ëœë¤ ìƒ˜í”Œë§
        indices = np.random.choice(len(points), max_points, replace=False)
        points = points[indices]
    
    # Open3D PointCloud ìƒì„±
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)
    
    if color is not None:
        # ë‹¨ì¼ ìƒ‰ìƒ ì ìš©
        pcd.paint_uniform_color(color)
    else:
        # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ (íšŒìƒ‰ì¡°)
        distances = np.linalg.norm(points, axis=1)
        max_dist = np.percentile(distances, 95)  # 95 percentileë¡œ ìŠ¤ì¼€ì¼ë§
        normalized_distances = np.clip(distances / max_dist, 0, 1)
        
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš°ë©´ ë°ì€ íšŒìƒ‰, ë©€ë©´ ì–´ë‘ìš´ íšŒìƒ‰
        colors = np.column_stack([1 - normalized_distances * 0.7] * 3)
        pcd.colors = o3d.utility.Vector3dVector(colors)
    
    return pcd


# noinspection PyBroadException
def visualize_ego_translations_open3d(gaussian_boxes: Optional[EvalBoxes] = None, 
                                     pred_boxes: Optional[EvalBoxes] = None, 
                                     gt_boxes: Optional[EvalBoxes] = None, 
                                     scene_name: Optional[str] = None,
                                     score_threshold: Optional[float] = None, 
                                     save_path: Optional[str] = None, 
                                     max_boxes: int = -1,
                                     sample_token: Optional[str] = None,
                                     show_lidar: bool = False,
                                     nusc: Optional[NuScenes] = None,
                                     max_lidar_points: int = 50000) -> None:
    """Open3Dë¥¼ ì´ìš©í•˜ì—¬ gaussian_boxes, pred_boxes, gt_boxesë¥¼ 3Dë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

    Args:
        gaussian_boxes: Gaussian ë°•ìŠ¤ë“¤ (ë¹¨ê°„ìƒ‰)
        pred_boxes: ì˜ˆì¸¡ ë°•ìŠ¤ë“¤ (íŒŒë€ìƒ‰)
        gt_boxes: Ground truth ë°•ìŠ¤ë“¤ (ì´ˆë¡ìƒ‰)
        scene_name: (ì„ íƒ) scene ì´ë¦„ (ì œëª© í‘œì‹œìš©)
        score_threshold: (ì„ íƒ) score threshold (ì œëª© í‘œì‹œìš©)
        save_path: (ì„ íƒ) ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        max_boxes: ìµœëŒ€ ë°•ìŠ¤ ê°œìˆ˜
        sample_token: (ì„ íƒ) íŠ¹ì • sampleë§Œ ì‹œê°í™”
        show_lidar: LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í‘œì‹œ ì—¬ë¶€
        nusc: NuScenes ê°ì²´ (LiDAR ë°ì´í„° ë¡œë”©ì— í•„ìš”)
        max_lidar_points: ìµœëŒ€ LiDAR í¬ì¸íŠ¸ ê°œìˆ˜
    """

    geometries = []

    # Coordinate frame ì¶”ê°€
    geometries.append(o3d.geometry.TriangleMesh.create_coordinate_frame(size=5.0))

    gaussian_count, pred_count, gt_count = 0, 0, 0
    center_translation = None

    # sample_tokenì´ ì§€ì •ëœ ê²½ìš° í•´ë‹¹ sampleì˜ ë°•ìŠ¤ë“¤ë§Œ ì‚¬ìš©
    sample_tokens_to_process = []
    
    # ì²˜ë¦¬í•  sample_tokens ê²°ì •
    if sample_token:
        # íŠ¹ì • sampleë§Œ ì²˜ë¦¬
        for boxes in [gaussian_boxes, pred_boxes, gt_boxes]:
            if boxes is not None and sample_token in boxes.sample_tokens:
                sample_tokens_to_process = [sample_token]
                break
        if not sample_tokens_to_process:
            print(f"âš ï¸ Sample token '{sample_token}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        # ëª¨ë“  sample ì²˜ë¦¬ (ê¸°ì¡´ ë™ì‘)
        all_sample_tokens = set()
        for boxes in [gaussian_boxes, pred_boxes, gt_boxes]:
            if boxes is not None:
                all_sample_tokens.update(boxes.sample_tokens)
        sample_tokens_to_process = list(all_sample_tokens)

    # ì²« ë²ˆì§¸ ë°•ìŠ¤ì˜ translationì„ centerë¡œ ì„¤ì •
    for sample_token_iter in sample_tokens_to_process:
        for boxes in [gaussian_boxes, pred_boxes, gt_boxes]:
            if boxes is not None and sample_token_iter in boxes.sample_tokens:
                for box in boxes[sample_token_iter]:
                    if (hasattr(box, 'translation') and box.translation is not None and
                            hasattr(box, 'size') and box.size is not None and
                            hasattr(box, 'rotation') and box.rotation is not None):
                        center_translation = np.array(box.translation)
                        break
                if center_translation is not None:
                    break
            if center_translation is not None:
                break
        if center_translation is not None:
            break

    if center_translation is None:
        print("ê¸°ì¤€ì´ ë  ë°•ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ì¶”ê°€ (íŠ¹ì • sampleì´ ì§€ì •ëœ ê²½ìš°ì—ë§Œ)
    if show_lidar and nusc is not None and sample_token is not None:
        print(f"ğŸ” LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ ë¡œë”© ì¤‘... (sample: {sample_token[:8]}...)")
        lidar_points = load_lidar_pointcloud(nusc, sample_token)
        if lidar_points is not None:
            print(f"âœ… {len(lidar_points):,}ê°œì˜ LiDAR í¬ì¸íŠ¸ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")  
            # Open3D PointCloud ìƒì„± ë° ì¶”ê°€
            lidar_pcd = create_open3d_pointcloud(lidar_points, 
                                               color=(0.5, 0.5, 0.5),  # íšŒìƒ‰
                                               max_points=max_lidar_points)
            geometries.append(lidar_pcd)
        else:
            print("âš ï¸ LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    elif show_lidar and sample_token is None:
        print("âš ï¸ LiDAR ì‹œê°í™”ëŠ” íŠ¹ì • sampleì´ ì§€ì •ëœ ê²½ìš°ì—ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. --sample_tokenì„ ì‚¬ìš©í•˜ì„¸ìš”.")

    # íŠ¹ì • sample ì‹œê°í™” ì‹œ ego ì¢Œí‘œê³„ ì‚¬ìš©, ì „ì²´ ì‹œê°í™” ì‹œ global ì¢Œí‘œê³„ ì‚¬ìš©
    use_ego_coordinates = sample_token is not None and len(sample_tokens_to_process) == 1

    # ì²˜ë¦¬í•  sampleë“¤ì— ëŒ€í•´ì„œë§Œ ë°•ìŠ¤ ì¶”ê°€
    for sample_token_iter in sample_tokens_to_process:
        # Gaussian boxes (Red)
        if gaussian_boxes is not None and sample_token_iter in gaussian_boxes.sample_tokens:
            for box in gaussian_boxes[sample_token_iter]:
                if max_boxes > 0 and gaussian_count >= max_boxes:
                    break  # ê°œìˆ˜ ì œí•œ ë„ë‹¬
                if (hasattr(box, 'translation') and box.translation is not None and
                        hasattr(box, 'size') and box.size is not None and
                        hasattr(box, 'rotation') and box.rotation is not None):
                    
                    # ego ì¢Œí‘œê³„ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì¢Œí‘œ ì„ íƒ
                    if use_ego_coordinates and hasattr(box, 'ego_translation') and hasattr(box, 'ego_rotation'):
                        translation = box.ego_translation  # type: ignore
                        rotation = getattr(box, 'ego_rotation')  # type: ignore
                        relative_translation = np.array(translation)
                    else:
                        # center ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚° (ê¸°ì¡´ ë°©ì‹)
                        relative_translation = np.array(box.translation) - center_translation
                        rotation = box.rotation
                    
                    corners = get_box_corners(relative_translation, box.size, rotation)
                    geometries.append(create_open3d_box(corners, (1.0, 0.0, 0.0)))  # Red

                    # ì•ë©´ ì¤‘ì‹¬ì  ì‹œê°í™” (Red)
                    front_center = (corners[1] + corners[6]) / 2 
                    geometries.append(create_open3d_sphere(front_center, radius=0.1, color=(1.0, 0.0, 0.0)))

                    gaussian_count += 1
            if max_boxes > 0 and gaussian_count >= max_boxes:
                break

        # Prediction boxes (Blue)
        if pred_boxes is not None and sample_token_iter in pred_boxes.sample_tokens:
            for box in pred_boxes[sample_token_iter]:
                if max_boxes > 0 and pred_count >= max_boxes:
                    break  # ê°œìˆ˜ ì œí•œ ë„ë‹¬
                if (hasattr(box, 'translation') and box.translation is not None and
                        hasattr(box, 'size') and box.size is not None and
                        hasattr(box, 'rotation') and box.rotation is not None):
                    
                    # ego ì¢Œí‘œê³„ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì¢Œí‘œ ì„ íƒ
                    if use_ego_coordinates and hasattr(box, 'ego_translation') and hasattr(box, 'ego_rotation'):
                        translation = box.ego_translation  # type: ignore
                        rotation = getattr(box, 'ego_rotation')  # type: ignore
                        relative_translation = np.array(translation)
                    else:
                        # center ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚° (ê¸°ì¡´ ë°©ì‹)
                        relative_translation = np.array(box.translation) - center_translation
                        rotation = box.rotation
                    
                    corners = get_box_corners(relative_translation, box.size, rotation)
                    geometries.append(create_open3d_box(corners, (0.0, 0.0, 1.0)))  # Blue

                    # ì•ë©´ ì¤‘ì‹¬ì  ì‹œê°í™” (Blue)
                    front_center = (corners[1] + corners[6]) / 2 
                    geometries.append(create_open3d_sphere(front_center, radius=0.1, color=(0.0, 0.0, 1.0)))

                    pred_count += 1
            if max_boxes > 0 and pred_count >= max_boxes:
                break

        # Ground truth boxes (black)
        if gt_boxes is not None and sample_token_iter in gt_boxes.sample_tokens:
            for box in gt_boxes[sample_token_iter]:
                if max_boxes > 0 and gt_count >= max_boxes:
                    break  # ê°œìˆ˜ ì œí•œ ë„ë‹¬
                if (hasattr(box, 'translation') and box.translation is not None and
                        hasattr(box, 'size') and box.size is not None and
                        hasattr(box, 'rotation') and box.rotation is not None):

                    # ego ì¢Œí‘œê³„ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ì¢Œí‘œ ì„ íƒ
                    if use_ego_coordinates and hasattr(box, 'ego_translation') and hasattr(box, 'ego_rotation'):
                        translation = box.ego_translation  # type: ignore
                        rotation = getattr(box, 'ego_rotation')  # type: ignore
                        relative_translation = np.array(translation)
                    else:
                        # center ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ìœ„ì¹˜ ê³„ì‚° (ê¸°ì¡´ ë°©ì‹)
                        relative_translation = np.array(box.translation) - center_translation
                        rotation = box.rotation
                    
                    corners = get_box_corners(relative_translation, box.size, rotation)
                    geometries.append(create_open3d_box(corners, (0.0, 0.0, 0.0)))  # Green

                    # ì•ë©´ ì¤‘ì‹¬ì  ì‹œê°í™” (Green)
                    front_center = (corners[1] + corners[6]) / 2 
                    geometries.append(create_open3d_sphere(front_center, radius=0.1, color=(0.0, 0.0, 0.0)))

                    gt_count += 1
            if max_boxes > 0 and gt_count >= max_boxes:
                break

        if max_boxes > 0 and (gaussian_count + pred_count + gt_count) >= max_boxes:
            break

    if gaussian_count == 0 and pred_count == 0 and gt_count == 0:
        print("ì‹œê°í™”í•  ë°•ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìœˆë„ìš° ì´ë¦„ ì„¤ì •
    window_name = "Open3D Visualization of Detection Boxes"
    subtitle_parts = []
    if scene_name:
        subtitle_parts.append(f"Scene: {scene_name}")
    if sample_token:
        subtitle_parts.append(f"Sample: {sample_token[:8]}...")
    if score_threshold is not None and score_threshold > 0:
        subtitle_parts.append(f"Scoreâ‰¥{score_threshold}")
    subtitle_parts.append(f"Gaussian: {gaussian_count}, Pred: {pred_count}, GT: {gt_count}")
    if subtitle_parts:
        window_name += " (" + " | ".join(subtitle_parts) + ")"

    # ---------------------------
    # ì‹œê°í™” (ì˜¨ìŠ¤í¬ë¦° or ì˜¤í”„ìŠ¤í¬ë¦°)
    # ---------------------------

    # 1) ì˜¤í”„ìŠ¤í¬ë¦° ë Œë”ë§ ëª¨ë“œê°€ í•„ìš”í•œ ê²½ìš° (save_path ì§€ì • or GUI ì‚¬ìš© ë¶ˆê°€)
    if save_path is not None:
        try:
            # ì €ì¥ ê²½ë¡œ ë””ë ‰í† ë¦¬ ìƒì„±
            save_dir = os.path.dirname(save_path)
            if save_dir and not os.path.exists(save_dir):
                os.makedirs(save_dir, exist_ok=True)
                print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìƒì„±: {save_dir}")
            
            print(f"ğŸ¨ ì˜¤í”„ìŠ¤í¬ë¦° ë Œë”ë§ ì‹œì‘... ({len(geometries)}ê°œ ê°ì²´)")
            success = False 
            
            vis = o3d.visualization.Visualizer()  # type: ignore
            # vis.create_window(visible=False, width=1920, height=1080)
            vis.create_window(visible=False, width=3840, height=2160)
            
            # ë Œë”ë§ ì˜µì…˜ ì„¤ì •
            render_option = vis.get_render_option()
            render_option.background_color = np.array([1, 1, 1])
            render_option.point_size = 6.0
            # render_option.line_width = 8.0  # ë°•ìŠ¤ ì„ ì„ ë” ë‘ê»ê²Œ ì„¤ì •
            
            # ê¸°í•˜í•™ì  ê°ì²´ë“¤ ì¶”ê°€
            for g in geometries:
                vis.add_geometry(g)
            
            # --------------------------------------
            # ì¹´ë©”ë¼ ì‹œì : Top-Down(ì¡°ê°) ë·°ë¡œ ë³€ê²½
            #   â€¢ front : (0, 0, -1)  â†’ ìœ„ì—ì„œ ì•„ë˜ë¡œ ë‚´ë ¤ë‹¤ë´„
            #   â€¢ up    : (0, -1, 0) â†’ Y-ì¶•ì„ í™”ë©´ ìœ„ìª½ìœ¼ë¡œ ì§€ì •
            # --------------------------------------
            ctr = vis.get_view_control()
            ctr.set_front([0, 0, -1])   # ì¹´ë©”ë¼ê°€ -Z ë°©í–¥(ì•„ë˜)ìœ¼ë¡œ ë°”ë¼ë³´ë„ë¡ ì„¤ì •
            ctr.set_up([0, -1, 0])      # í™”ë©´ì˜ ìœ„ìª½ì„ -Y ë°©í–¥ìœ¼ë¡œ ë§ì¶¤ (XY í‰ë©´ ê¸°ì¤€)
            ctr.set_lookat([0, 0, 0])   # ì›ì (ì„¼ì„œ ìœ„ì¹˜)ì„ ë°”ë¼ë³´ë„ë¡ ì„¤ì •
            
            # --------------------------------------
            # ì§êµ íˆ¬ì˜(Orthographic Projection) í™œì„±í™”
            #   â†’ ì›ê·¼ë²• ì—†ì´ ëª¨ë“  ê°ì²´ê°€ ë™ì¼í•œ ìŠ¤ì¼€ì¼ë¡œ ë³´ì´ë„ë¡ ì„¤ì •
            # --------------------------------------
            # Open3Dì—ì„œ ì§êµ íˆ¬ì˜ì„ ìœ„í•´ field of viewë¥¼ ë§¤ìš° ì‘ê²Œ ì„¤ì •
            # ì´ë ‡ê²Œ í•˜ë©´ ì›ê·¼ë²• íš¨ê³¼ê°€ ê±°ì˜ ì‚¬ë¼ì ¸ì„œ ì§êµ íˆ¬ì˜ê³¼ ìœ ì‚¬í•œ íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ
            ctr.change_field_of_view(step=-500)  # FOVë¥¼ ë§¤ìš° ì‘ê²Œ ì„¤ì •í•˜ì—¬ ì§êµ íˆ¬ì˜ íš¨ê³¼
            ctr.set_zoom(0.15)  # ì ì ˆí•œ ì¤Œ ë ˆë²¨ ì„¤ì •

            
            # ì—¬ëŸ¬ ë²ˆ ë Œë”ë§í•˜ì—¬ ì•ˆì •í™”
            for _ in range(3):
                vis.poll_events()
                vis.update_renderer()
            
            # Float bufferë¡œ ì´ë¯¸ì§€ ìº¡ì²˜ (ë” ì•ˆì •ì )
            try:
                image = vis.capture_screen_float_buffer(do_render=True)
                image_np = np.asarray(image)
                
                # Float bufferë¥¼ 0-255 ë²”ìœ„ë¡œ ë³€í™˜
                if image_np.max() <= 1.0:
                    image_np = (image_np * 255).astype(np.uint8)
                
                # PILë¡œ ì´ë¯¸ì§€ ì €ì¥
                from PIL import Image
                pil_image = Image.fromarray(image_np)
                pil_image.save(save_path)
                success = True
                
            except Exception as e2:
                print(f"âš ï¸ Float buffer ë°©ë²• ì‹¤íŒ¨: {e2}")
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê¸°ë³¸ capture_screen_image
                success = vis.capture_screen_image(save_path)
            
            vis.destroy_window()
            
            # ê²°ê³¼ í™•ì¸ ë° í”¼ë“œë°±
            if success and os.path.exists(save_path):
                file_size = os.path.getsize(save_path)
                if file_size > 1000:  # ìµœì†Œ 1KB ì´ìƒì´ì–´ì•¼ ìœ íš¨í•œ ì´ë¯¸ì§€
                    print(f"âœ… 3D ì‹œê°í™” ê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
                    print(f"   ğŸ“‚ ê²½ë¡œ: {save_path}")
                    print(f"   ğŸ“Š í¬ê¸°: {file_size:,} bytes")
                else:
                    print(f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {file_size} bytes")
            else:
                print(f"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {save_path}")
                
        except Exception as e:
            print(f"âš ï¸ ì „ì²´ ë Œë”ë§ ê³¼ì • ì‹¤íŒ¨: {e}")
            print(f"   ğŸ’¡ ëŒ€ì•ˆ: GUI ëª¨ë“œë¡œ ì‹œê°í™”í•˜ë ¤ë©´ --save_plot ì˜µì…˜ì„ ì œê±°í•˜ì„¸ìš”.")
        return

    # 2) ì¼ë°˜ ìœˆë„ìš° ëª¨ë“œ (GUI ê°€ëŠ¥ í™˜ê²½)
    try:
        o3d.visualization.draw_geometries(geometries, window_name=window_name)  # type: ignore
    except Exception as e:
        print("âš ï¸ Open3D GUI ì°½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (Headless í™˜ê²½ìœ¼ë¡œ íŒë‹¨)\n   â†’ ì˜¤ë¥˜ ë©”ì‹œì§€:", e)
        print("ëŒ€ì‹  ì˜¤í”„ìŠ¤í¬ë¦° ëª¨ë“œë¡œ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤. '--save_plot <ê²½ë¡œ>' ì¸ìë¥¼ ì§€ì •í•˜ì„¸ìš”.")


def visualize_all_samples_individually(gaussian_boxes: Optional[EvalBoxes] = None, 
                                      pred_boxes: Optional[EvalBoxes] = None, 
                                      gt_boxes: Optional[EvalBoxes] = None, 
                                      scene_name: Optional[str] = None,
                                      score_threshold: Optional[float] = None, 
                                      save_dir: Optional[str] = None, 
                                      max_boxes: int = -1,
                                      max_samples: int = -1,
                                      show_lidar: bool = False,
                                      nusc: Optional[NuScenes] = None,
                                      max_lidar_points: int = 50000) -> None:
    """ëª¨ë“  sampleì„ ê°œë³„ì ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
    
    Args:
        gaussian_boxes: Gaussian ë°•ìŠ¤ë“¤
        pred_boxes: ì˜ˆì¸¡ ë°•ìŠ¤ë“¤  
        gt_boxes: Ground truth ë°•ìŠ¤ë“¤
        scene_name: scene ì´ë¦„
        score_threshold: score threshold
        save_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ (ì§€ì •í•˜ë©´ ê° sampleë³„ë¡œ íŒŒì¼ ì €ì¥)
        max_boxes: ìƒ˜í”Œë‹¹ ìµœëŒ€ ë°•ìŠ¤ ê°œìˆ˜
        max_samples: ì²˜ë¦¬í•  ìµœëŒ€ ìƒ˜í”Œ ê°œìˆ˜
        show_lidar: LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œ í‘œì‹œ ì—¬ë¶€
        nusc: NuScenes ê°ì²´ (LiDAR ë°ì´í„° ë¡œë”©ì— í•„ìš”)
        max_lidar_points: ìµœëŒ€ LiDAR í¬ì¸íŠ¸ ê°œìˆ˜
    """
    sample_tokens = []

    # ì‹œê°„ ìˆœì„œëŒ€ë¡œ sample_tokens ìˆ˜ì§‘
    if nusc and scene_name:
        # scene ì •ë³´ì—ì„œ ì‹œê°„ ìˆœì„œëŒ€ë¡œ sample_tokens ê°€ì ¸ì˜¤ê¸°
        scene_token = None
        for scene in nusc.scene:
            if scene['name'] == scene_name:
                scene_token = scene['token']
                break
        
        if scene_token:
            # í•´ë‹¹ scene ì°¾ê¸°
            scene = nusc.get('scene', scene_token)
            
            # sceneì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œë¶€í„° ì‹œì‘í•˜ì—¬ ì‹œê°„ìˆœìœ¼ë¡œ ìˆ˜ì§‘
            sample = nusc.get('sample', scene['first_sample_token'])
            scene_sample_tokens = []
            
            while True:
                scene_sample_tokens.append(sample['token'])
                if sample['next'] == '':
                    break
                sample = nusc.get('sample', sample['next'])
            
            # ìˆ˜ì§‘ëœ sceneì˜ sample_tokens ì¤‘ì—ì„œ ì‹¤ì œ ë°•ìŠ¤ ë°ì´í„°ê°€ ìˆëŠ” ê²ƒë§Œ í•„í„°ë§
            available_sample_tokens = set()
            for boxes in [gaussian_boxes, pred_boxes, gt_boxes]:
                if boxes is not None:
                    available_sample_tokens.update(boxes.sample_tokens)
            
            # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ sample_tokens ì¤‘ì—ì„œ ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ” ê²ƒë§Œ ìœ ì§€
            sample_tokens = [token for token in scene_sample_tokens if token in available_sample_tokens]
        else:
            print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    else:
        # nuscë‚˜ scene_nameì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš© (ìˆœì„œ ë³´ì¥ ì•ˆë¨)
        if gt_boxes:    
            sample_tokens = list(gt_boxes.sample_tokens)
        elif pred_boxes:
            sample_tokens = list(pred_boxes.sample_tokens)
        elif gaussian_boxes:
            sample_tokens = list(gaussian_boxes.sample_tokens)
    
    if max_samples > 0:
        sample_tokens = sample_tokens[:max_samples]
    
    print(f"ğŸ“Š ì´ {len(sample_tokens)}ê°œì˜ sampleì„ ê°œë³„ì ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤...")
    
    if save_dir:
        os.makedirs(save_dir, exist_ok=True)
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì„ '{save_dir}' ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.")
    
    for i, sample_token in enumerate(sample_tokens):
        print(f"ğŸ¯ Processing sample {i+1}/{len(sample_tokens)}: {sample_token}")
        
        save_path = None
        if save_dir:
            # scene ì´ë¦„ìœ¼ë¡œ í•˜ìœ„ í´ë” ìƒì„±
            if scene_name:
                scene_dir = os.path.join(save_dir, scene_name)
                os.makedirs(scene_dir, exist_ok=True)
                # 2ìë¦¬ ì¸ë±ìŠ¤ë¡œ íŒŒì¼ëª… ìƒì„±
                save_path = os.path.join(scene_dir, f"sample_{i:02d}_{sample_token}.png")
            else:
                # scene_nameì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ save_dir ì‚¬ìš©
                save_path = os.path.join(save_dir, f"sample_{i:02d}_{sample_token}.png")
        
        visualize_ego_translations_open3d(
            gaussian_boxes=gaussian_boxes,
            pred_boxes=pred_boxes, 
            gt_boxes=gt_boxes,
            scene_name=scene_name,
            score_threshold=score_threshold,
            save_path=save_path,
            max_boxes=max_boxes,
            sample_token=sample_token,
            show_lidar=show_lidar,
            nusc=nusc,
            max_lidar_points=max_lidar_points
        )
        
        if not save_dir:
            # GUI ëª¨ë“œì¼ ë•ŒëŠ” ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
            input("ë‹¤ìŒ sampleë¡œ ì´ë™í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”... (Ctrl+Cë¡œ ì¢…ë£Œ)")

# -----------------------------------------------------------------------------
# ë°•ìŠ¤ í•„í„°ë§ ìœ í‹¸ë¦¬í‹° (Score / Scene)
# -----------------------------------------------------------------------------

def filter_boxes_by_score(boxes: EvalBoxes, score_threshold: float) -> EvalBoxes:
    """detection_scoreê°€ threshold ì´ìƒì¸ boxesë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        boxes: í•„í„°ë§í•  EvalBoxes
        score_threshold: score threshold (ì´ ê°’ ì´ìƒì¸ ë°•ìŠ¤ë“¤ë§Œ ìœ ì§€)

    Returns:
        í•„í„°ë§ëœ EvalBoxes
    """
    filtered_boxes = EvalBoxes()
    total_boxes = 0
    filtered_count = 0

    for sample_token in boxes.sample_tokens:
        sample_boxes = []
        for box in boxes[sample_token]:
            total_boxes += 1
            if hasattr(box, 'detection_score') and box.detection_score >= score_threshold:
                sample_boxes.append(box)
                filtered_count += 1

        if sample_boxes:  # í•„í„°ë§ëœ ë°•ìŠ¤ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
            filtered_boxes.add_boxes(sample_token, sample_boxes)

    print(f"âœ… Score {score_threshold} ì´ìƒì¸ ë°•ìŠ¤: {filtered_count}/{total_boxes}ê°œ")
    return filtered_boxes


def filter_boxes_by_scene(nusc: NuScenes, boxes: EvalBoxes, scene_name: str) -> EvalBoxes:
    """íŠ¹ì • sceneì— í•´ë‹¹í•˜ëŠ” boxesë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        nusc: NuScenes ê°ì²´
        boxes: í•„í„°ë§í•  EvalBoxes
        scene_name: í•„í„°ë§í•  scene ì´ë¦„ (ì˜ˆ: 'scene-0061')

    Returns:
        í•„í„°ë§ëœ EvalBoxes
    """
    # scene ì´ë¦„ìœ¼ë¡œ scene ì°¾ê¸°
    scene_token = None
    for scene in nusc.scene:
        if scene['name'] == scene_name:
            scene_token = scene['token']
            break

    if scene_token is None:
        print(f"âš ï¸ Scene '{scene_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return EvalBoxes()

    # í•´ë‹¹ sceneì˜ sample_tokens ê°€ì ¸ì˜¤ê¸°
    scene_sample_tokens = []
    for sample_token in boxes.sample_tokens:
        sample = nusc.get('sample', sample_token)
        if sample['scene_token'] == scene_token:
            scene_sample_tokens.append(sample_token)

    # í•„í„°ë§ëœ ë°•ìŠ¤ë“¤ë¡œ ìƒˆë¡œìš´ EvalBoxes ìƒì„±
    filtered_boxes = EvalBoxes()
    for sample_token in scene_sample_tokens:
        if sample_token in boxes.sample_tokens:
            filtered_boxes.add_boxes(sample_token, boxes[sample_token])

    print(f"âœ… Scene '{scene_name}'ì—ì„œ {len(scene_sample_tokens)}ê°œì˜ ìƒ˜í”Œì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    return filtered_boxes


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Visualize Gaussian, Prediction, and Ground Truth boxes")
    parser.add_argument(
        "--gaussian_boxes",
        type=str,
        default='/workspace/drivestudio/output/feasibility_check/updated/poses_selected_tar_selected_src.json',
        help="Path to gaussian boxes json file",
    )
    parser.add_argument(
        "--pred_boxes",
        type=str,
        default='/workspace/drivestudio/output/ceterpoint_pose/results_nusc_selected_tar_selected_tar.json',
        help="Path to prediction boxes json file",
    )
    parser.add_argument(
        "--gt_boxes",
        type=str,
        default='/workspace/drivestudio/output/ceterpoint_pose/results_nusc_gt_pred_selected_src_selected_tar.json',
        help="Path to ground truth boxes json file",
    )
    parser.add_argument(
        "--version",
        type=str,
        default="v1.0-mini",
        help="NuScenes version",
    )
    parser.add_argument(
        "--dataroot",
        type=str,
        default="/workspace/drivestudio/data/nuscenes/raw",
        help="NuScenes dataroot",
    )
    parser.add_argument(
        "--verbose",
        type=bool,
        default=False,
        help="Verbose",
    )
    parser.add_argument(
        "--save_plot",
        type=str,
        # default=None,
        default='/workspace/drivestudio/output/feasibility_check/updated/plots',
        help="Path to save the 3D visualization plot"
    )
    parser.add_argument(
        "--scene_name",
        type=str,
        default='scene-0061',
        help="Scene name to filter boxes"
    )
    parser.add_argument(
        "--score_threshold",
        type=float,
        default=0.0,
        help="Minimum detection score threshold for prediction boxes"
    )
    parser.add_argument(
        "--max_boxes",
        type=int,
        default=1500,
        help="ì‹œê°í™”í•  ìµœëŒ€ ë°•ìŠ¤ ê°œìˆ˜ (<=0 ì´ë©´ ì œí•œ ì—†ìŒ)"
    )
    parser.add_argument(
        "--sample_token",
        type=str,
        default=None,
        help="íŠ¹ì • sampleë§Œ ì‹œê°í™” (sample token ì§€ì •)"
    )
    parser.add_argument(
        "--visualize_individual_samples",
        type=bool,
        default=True,
        help="ëª¨ë“  sampleì„ ê°œë³„ì ìœ¼ë¡œ ì‹œê°í™”"
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=-1,
        help="ê°œë³„ ì‹œê°í™”í•  ìµœëŒ€ sample ê°œìˆ˜ (<=0 ì´ë©´ ì œí•œ ì—†ìŒ)"
    )
    parser.add_argument(
        "--show_lidar",
        type=bool,
        default=True,
        help="LiDAR í¬ì¸íŠ¸ í´ë¼ìš°ë“œë„ í•¨ê»˜ ì‹œê°í™”"
    )
    parser.add_argument(
        "--max_lidar_points",
        type=int,
        default=50000,
        help="ì‹œê°í™”í•  ìµœëŒ€ LiDAR í¬ì¸íŠ¸ ê°œìˆ˜"
    )

    args = parser.parse_args()

    # ìµœì†Œ í•˜ë‚˜ì˜ ë°•ìŠ¤ íŒŒì¼ì€ ì œê³µë˜ì–´ì•¼ í•¨
    if not any([args.gaussian_boxes, args.pred_boxes, args.gt_boxes]):
        print("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ë°•ìŠ¤ íŒŒì¼ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤ (--gaussian_boxes, --pred_boxes, --gt_boxes ì¤‘ í•˜ë‚˜)")
        return

    nusc = NuScenes(version=args.version, dataroot=args.dataroot, verbose=args.verbose)
    
    config = config_factory('detection_cvpr_2019')

    gaussian_boxes = None
    pred_boxes = None
    gt_boxes = None

    # Load gaussian boxes if provided
    if args.gaussian_boxes and os.path.exists(args.gaussian_boxes):
        print(f"ğŸ“Š Gaussian boxes ë¡œë”© ì¤‘: {args.gaussian_boxes}")
        gaussian_boxes, _ = load_prediction(args.gaussian_boxes, 
                                           config.max_boxes_per_sample, 
                                           DetectionBox,
                                           verbose=args.verbose)

    # Load prediction boxes if provided
    if args.pred_boxes and os.path.exists(args.pred_boxes):
        print(f"ğŸ“Š Prediction boxes ë¡œë”© ì¤‘: {args.pred_boxes}")
        pred_boxes, _ = load_prediction(args.pred_boxes, 
                                       config.max_boxes_per_sample, 
                                       DetectionBox,
                                       verbose=args.verbose)

    # Load ground truth boxes if provided
    if args.gt_boxes and os.path.exists(args.gt_boxes):
        print(f"ğŸ“Š Ground truth boxes ë¡œë”© ì¤‘: {args.gt_boxes}")
        gt_boxes, _ = load_prediction(args.gt_boxes, 
                                     config.max_boxes_per_sample, 
                                     DetectionBox,
                                     verbose=args.verbose)

    # Filter by score threshold if prediction boxes exist
    if pred_boxes and args.score_threshold > 0:
        print(f"ğŸ“Š Score threshold {args.score_threshold}ë¡œ pred_boxes í•„í„°ë§ ì¤‘...")
        pred_boxes = filter_boxes_by_score(pred_boxes, args.score_threshold)
    
    # Filter boxes by scene
    if args.scene_name:
        if gaussian_boxes:
            gaussian_boxes = filter_boxes_by_scene(nusc, gaussian_boxes, args.scene_name)
        if pred_boxes:
            pred_boxes = filter_boxes_by_scene(nusc, pred_boxes, args.scene_name)
        if gt_boxes:
            gt_boxes = filter_boxes_by_scene(nusc, gt_boxes, args.scene_name)

    # Add ego pose information to all boxes
    if gaussian_boxes:
        gaussian_boxes = add_ego_pose(nusc, gaussian_boxes)
    if pred_boxes:
        pred_boxes = add_ego_pose(nusc, pred_boxes)
    if gt_boxes:
        gt_boxes = add_ego_pose(nusc, gt_boxes)

    # Open3D 3D ì‹œê°í™”
    if args.visualize_individual_samples:
        # ëª¨ë“  sampleì„ ê°œë³„ì ìœ¼ë¡œ ì‹œê°í™”
        print("ëª¨ë“  sampleì„ ê°œë³„ì ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤...")
        visualize_all_samples_individually(
            gaussian_boxes=gaussian_boxes,
            pred_boxes=pred_boxes, 
            gt_boxes=gt_boxes,
            scene_name=args.scene_name,
            score_threshold=args.score_threshold,
            save_dir=args.save_plot,
            max_boxes=args.max_boxes,
            max_samples=args.max_samples,
            show_lidar=args.show_lidar,
            nusc=nusc,
            max_lidar_points=args.max_lidar_points
        )
    else:
        # ê¸°ì¡´ ë°©ì‹: ëª¨ë“  ë°•ìŠ¤ë¥¼ í•œë²ˆì— ì‹œê°í™” ë˜ëŠ” íŠ¹ì • sampleë§Œ ì‹œê°í™”
        print("Open3D 3D ì‹œê°í™”ë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        visualize_ego_translations_open3d(
            gaussian_boxes=gaussian_boxes,
            pred_boxes=pred_boxes, 
            gt_boxes=gt_boxes, 
            scene_name=args.scene_name, 
            score_threshold=args.score_threshold, 
            save_path=args.save_plot, 
            max_boxes=args.max_boxes,
            sample_token=args.sample_token,
            show_lidar=args.show_lidar,
            nusc=nusc,
            max_lidar_points=args.max_lidar_points
        )

if __name__ == "__main__":
    main()
    
