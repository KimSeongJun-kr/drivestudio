# 1. Build Docker Image
docker build -t drivestudio:0.0.1 .

# 2. Environment Setup
## Run Docker Container
xhost +local:root
docker run --gpus '"device=0"' -it --shm-size=16g \
    -p 8080:8080 \
    -v "/home/aimlab/seongjun_ws/docker_ws/dynamic_3dgs_ws/drivestudio:/workspace/drivestudio" \
    -v "/media/aimlab/HDD02_1TB:/workspace/drivestudio/data" \
    -v "/usr/share/glvnd/egl_vendor.d:/usr/share/glvnd/egl_vendor.d/" \
    -e DISPLAY=$DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix \
    -e NVIDIA_DRIVER_CAPABILITIES=all \
    -e EGL_PLATFORM=surfaceless \
    --device=/dev/nvidia0 \
    --name drivestudio \
    drivestudio:0.0.1 /bin/bash

## (Every Time) Activate Conda Environment
conda activate drivestudio

## Install packages for animation (to be integrated in dockerfile)
apt-get update && apt-get install -y fonts-dejavu-core libegl1 libgl1 libgles2 libglvnd0
python3 -m pip install open3d==0.19.0

## Install packages for web viewer
python -m pip install --no-cache-dir \
  "git+https://github.com/nerfstudio-project/nerfview@main" \
  "git+https://github.com/nerfstudio-project/viser@main"
python -m pip install splines

# 3. Run OmniRe training
## Set Configuration
PROJECT_NAME="feasibility_check_0619"
RUN_NAME="run_updated_scene_0_date_0618_try_1"
DATASET_NAME="nuscenes/6cams_update"
## Optimization
python -m tools.train \
    --config_file configs/omnire_extended_cam.yaml \
    --output_root output \
    --project ${PROJECT_NAME} \
    --run_name ${RUN_NAME} \
    dataset=${DATASET_NAME} \
    data.scene_idx=0 \
    data.start_timestep=0 \
    data.end_timestep=-1
python -m tools.train \
    --config_file configs/omnire.yaml \
    --output_root output \
    --project ${PROJECT_NAME} \
    --run_name ${RUN_NAME} \
    dataset=${DATASET_NAME} \
    data.scene_idx=0 \
    data.start_timestep=0 \
    data.end_timestep=-1
# 4. Run 3D Bounding Box evaluation
## 코드 수정
file "/opt/conda/lib/python3.7/site-packages/nuscenes/utils/splits.py"
line 150: 'mini_val = mini_val + mini_train' 추가
## Run Evaluation
python seongjun_tools/evaluate_3dbb.py \
    --pred /workspace/drivestudio/output/feasibility_check/run_original_scene_0_date_0529_try_1/keyframe_instance_poses_data/all_poses.json \
    --version v1.0-mini \
    --dataroot /workspace/drivestudio/data/nuscenes/raw \
    --verbose True

# 4. 3D Bounding Box Visualization
python seongjun_tools/visualize_instances.py \
    --gaussian_boxes /workspace/drivestudio/output/feasibility_check/updated/poses_selected_tar_selected_src.json \
    --pred_boxes /workspace/drivestudio/output/ceterpoint_pose/results_nusc_selected_tar_selected_tar.json \
    --gt_boxes /workspace/drivestudio/output/ceterpoint_pose/results_nusc_gt_pred_selected_src_selected_tar.json \
    --version v1.0-mini \
    --dataroot /workspace/drivestudio/data/nuscenes/raw \

python seongjun_tools/visualize_instances.py \
    --gaussian_boxes /workspace/drivestudio/output/feasibility_check/updated/poses_selected_tar_selected_src.json \
    --pred_boxes /workspace/drivestudio/output/ceterpoint_pose/results_nusc_selected_tar_selected_tar.json \
    --gt_boxes /workspace/drivestudio/output/ceterpoint_pose/results_nusc_gt_pred_selected_src_selected_tar.json \
    --version v1.0-mini \
    --dataroot /workspace/drivestudio/data/nuscenes/raw \
    --save_dir /workspace/drivestudio/output/feasibility_check/updated/plots





# DATASET_DIR=/data/my_desk
# DATASET_DIR=/data/example_dataset_tmp
# DATASET_DIR=/data/lab_room
# DATASET_DIR="/media/aimlab/SSD_3DGS/3DGS/toy_dataset/example_dataset"
# DATASET_DIR="/media/aimlab/SSD_3DGS/3DGS/toy_dataset/my_desk"
# SIBR_viewers/install/bin/SIBR_gaussianHierarchyViewer_app --path ${DATASET_DIR}/camera_calibration/aligned --scaffold ${DATASET_DIR}/output/scaffold/point_cloud/iteration_30000 --model-path ${DATASET_DIR}/output/merged.hier --images-path ${DATASET_DIR}/camera_calibration/rectified/images
